{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install einops\n",
    "# %pip install peft\n",
    "!pip install trl\n",
    "# %pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'prepare_model_for_kbit_training' from 'peft' (c:\\Users\\danm\\Downloads\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\peft\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32me:\\src\\transformer-sketchbook\\notebooks\\finetune_phi2.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/finetune_phi2.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/finetune_phi2.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     AutoModelForCausalLM,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/finetune_phi2.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     AutoTokenizer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/finetune_phi2.ipynb#W1sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     TrainingArguments,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/finetune_phi2.ipynb#W1sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/finetune_phi2.ipynb#W1sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnotebook\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/finetune_phi2.ipynb#W1sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrl\u001b[39;00m \u001b[39mimport\u001b[39;00m SFTTrainer\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/finetune_phi2.ipynb#W1sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mhuggingface_hub\u001b[39;00m \u001b[39mimport\u001b[39;00m interpreter_login\n",
      "File \u001b[1;32mc:\\Users\\danm\\Downloads\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\trl\\__init__.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m set_seed\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39menvironment\u001b[39;00m \u001b[39mimport\u001b[39;00m TextEnvironment, TextHistory\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mextras\u001b[39;00m \u001b[39mimport\u001b[39;00m BestOfNSampler\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mimport_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     is_bitsandbytes_available,\n\u001b[0;32m     10\u001b[0m     is_diffusers_available,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     is_xpu_available,\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     17\u001b[0m     AutoModelForCausalLMWithValueHead,\n\u001b[0;32m     18\u001b[0m     AutoModelForSeq2SeqLMWithValueHead,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     setup_chat_format,\n\u001b[0;32m     22\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\danm\\Downloads\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\trl\\extras\\__init__.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# flake8: noqa\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[39m# Copyright 2022 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbest_of_n_sampler\u001b[39;00m \u001b[39mimport\u001b[39;00m BestOfNSampler\n",
      "File \u001b[1;32mc:\\Users\\danm\\Downloads\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\trl\\extras\\best_of_n_sampler.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m GenerationConfig, PreTrainedTokenizer, PreTrainedTokenizerFast\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m set_seed\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m SUPPORTED_ARCHITECTURES, PreTrainedModelWrapper\n\u001b[0;32m     10\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mBestOfNSampler\u001b[39;00m(\u001b[39mobject\u001b[39m):\n\u001b[0;32m     11\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m     12\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m     13\u001b[0m         model: PreTrainedModelWrapper,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m         generation_config: Optional[GenerationConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     21\u001b[0m     ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\danm\\Downloads\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\trl\\models\\__init__.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# flake8: noqa\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[39m# Copyright 2022 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodeling_base\u001b[39;00m \u001b[39mimport\u001b[39;00m PreTrainedModelWrapper, create_reference_model\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodeling_value_head\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoModelForCausalLMWithValueHead, AutoModelForSeq2SeqLMWithValueHead\n\u001b[0;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m setup_chat_format\n",
      "File \u001b[1;32mc:\\Users\\danm\\Downloads\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\trl\\models\\modeling_base.py:36\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimport_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m is_npu_available, is_peft_available, is_transformers_greater_than, is_xpu_available\n\u001b[0;32m     35\u001b[0m \u001b[39mif\u001b[39;00m is_peft_available():\n\u001b[1;32m---> 36\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpeft\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     37\u001b[0m         PeftConfig,\n\u001b[0;32m     38\u001b[0m         PeftModel,\n\u001b[0;32m     39\u001b[0m         PeftModelForCausalLM,\n\u001b[0;32m     40\u001b[0m         PeftModelForSeq2SeqLM,\n\u001b[0;32m     41\u001b[0m         PromptLearningConfig,\n\u001b[0;32m     42\u001b[0m         get_peft_model,\n\u001b[0;32m     43\u001b[0m         prepare_model_for_kbit_training,\n\u001b[0;32m     44\u001b[0m     )\n\u001b[0;32m     46\u001b[0m \u001b[39mif\u001b[39;00m is_transformers_greater_than(\u001b[39m\"\u001b[39m\u001b[39m4.33.0\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     47\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mintegrations\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdeepspeed\u001b[39;00m \u001b[39mimport\u001b[39;00m is_deepspeed_zero3_enabled\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'prepare_model_for_kbit_training' from 'peft' (c:\\Users\\danm\\Downloads\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\peft\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from datasets import load_from_disk\n",
    "from peft import LoraConfig\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from trl import SFTTrainer\n",
    "from huggingface_hub import interpreter_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/layoutlm/medquad.csv\")\n",
    "df = df.iloc[:,:2]\n",
    "df.columns = [\"text\",'label']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = list(df.to_json(orient=\"records\"))\n",
    "\n",
    "result[0] = '{\"json\":['\n",
    "result[-1] = ']'\n",
    "result.append('}')\n",
    "\n",
    "\n",
    "result = ''.join(result)\n",
    "result = result.strip('\"\\'')\n",
    "\n",
    "result = json.loads(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"json\", data_files=\"/kaggle/working/data.json\", field='json', split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"../models/phi-2\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LineByLineTextDataset\n",
    "\n",
    "dataset = LineByLineTextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"./twenty_years_of_baseball_structed_data.txt\",\n",
    "    block_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_compute_dtype='float16',\n",
    "    bnb_4bit_use_double_quant=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "r=32,\n",
    "lora_alpha=16,\n",
    "target_modules=[\n",
    "'Wqkv',\n",
    "'out_proj'\n",
    "],\n",
    "bias=\"none\",\n",
    "lora_dropout=0.05, # Conventional\n",
    "task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "        \"../models/phi-2\", \n",
    "        quantization_config=bnb_config, \n",
    "        device_map = 'auto',\n",
    "        trust_remote_code=True,\n",
    "        use_auth_token=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "output_dir= \"../models/phi-2-mlb/results\",\n",
    "num_train_epochs= 4,\n",
    "per_device_train_batch_size= 2,\n",
    "gradient_accumulation_steps= 1,\n",
    "optim=\"paged_adamw_32bit\",\n",
    "save_strategy=\"epoch\",\n",
    "logging_steps=100,\n",
    "logging_strategy=\"steps\",\n",
    "learning_rate= 2e-4,\n",
    "fp16= False,\n",
    "bf16= False,\n",
    "group_by_length= True,\n",
    "disable_tqdm=False,\n",
    "report_to=\"tensorboard\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=2048,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=False,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer('''Question: What is (are) Trigeminal Neuralgia ?\\n Output:''', return_tensors=\"pt\", return_attention_mask=False)\n",
    "outputs = model.generate(**inputs, max_length=200)\n",
    "text = tokenizer.batch_decode(outputs[0], skip_special_tokens=True)\n",
    "print(''.join(text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
