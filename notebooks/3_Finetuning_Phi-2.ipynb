{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install einops\n",
    "%pip install peft\n",
    "%pip install trl\n",
    "%pip install tensorboard\n",
    "%pip install -U transformers\n",
    "%pip install -U accelerate datasets \n",
    "%pip install -q https://github.com/jllllll/bitsandbytes-windows-webui/releases/download/wheels/bitsandbytes-0.41.1-py3-none-win_amd64.whl\n",
    "%pip install tokenizers==0.15.0\n",
    "%pip install torch==2.1.2+cu121 --index-url https://download.pytorch.org/whl/cu121\n",
    "%pip install torchaudio==2.1.2+cu121 --index-url https://download.pytorch.org/whl/cu121\n",
    "%pip install torchvision==0.16.2+cu121 --index-url https://download.pytorch.org/whl/cu121\n",
    "%pip install transformers==4.35.2\n",
    "%pip install ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset,DatasetDict\n",
    "from peft import LoraConfig\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments\n",
    ")\n",
    "from tqdm.notebook import tqdm\n",
    "from trl import SFTTrainer\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c20cdcd150401d9e0153145bb8e303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd7d8803a25f42da9f37cfb20dfd5d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d80deb08654b9ca9211089ba6606eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = load_dataset(\"json\", data_files='../data/2011_2023_train_test_valuation.json',field=\"train\", split='all')\n",
    "eval_dataset = load_dataset(\"json\", data_files='../data/2011_2023_train_test_valuation.json', field=\"valuation\", split='all') \n",
    "test_dataset = load_dataset(\"json\", data_files='../data/2011_2023_train_test_valuation.json', field=\"test\", split='all')\n",
    "\n",
    "dataset = DatasetDict(\n",
    "    {\n",
    "        \"train\":train_dataset,\n",
    "        \"validation\":eval_dataset,\n",
    "        \"test\":test_dataset\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'input', 'output'],\n",
       "        num_rows: 188478\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'input', 'output'],\n",
       "        num_rows: 12\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'input', 'output'],\n",
       "        num_rows: 1\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"../models/phi-2\", trust_remote_code=True)\n",
    "## Add Special Tokens\n",
    "tokenizer.add_tokens([\"[INST]\", \"<PAD>\"])\n",
    "tokenizer.pad_token = \"<PAD>\"\n",
    "tokenizer.add_special_tokens(dict(eos_token=\"</s>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_compute_dtype='float16',\n",
    "    bnb_4bit_use_double_quant=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\src\\transformer-sketchbook\\.venv\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:472: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin e:\\src\\transformer-sketchbook\\.venv\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda121.dll\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d999e7905ed42ec93fe4020fcb2963e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are calling `save_pretrained` to a 4-bit converted model, but your `bitsandbytes` version doesn't support it. If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "        \"../models/phi-2\", \n",
    "        quantization_config=bnb_config, \n",
    "        device_map = 'auto',\n",
    "        trust_remote_code=True,\n",
    "        use_auth_token=True,\n",
    "    )\n",
    "model.config.eos_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=True) \n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=32, \n",
    "    lora_alpha=32, \n",
    "    target_modules = [ \"q_proj\", \"k_proj\", \"v_proj\", \"dense\" ],\n",
    "    modules_to_save = [\"lm_head\", \"embed_tokens\"],\n",
    "    lora_dropout=0.1, \n",
    "    bias=\"none\", \n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1: # If more than 1 GPU\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset-specific parameters\n",
    "bs=8    # batch size for training\n",
    "bs_eval=16    # batch size for evaluation\n",
    "ga_steps=16  # gradient accumulation steps\n",
    "lr=0.00002  # learning rate\n",
    "epochs=1\n",
    "\n",
    "steps_per_epoch=len(dataset[\"train\"])//(bs*ga_steps)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"../models/phi-2-mlb\",\n",
    "    per_device_train_batch_size=bs,\n",
    "    per_device_eval_batch_size=bs_eval,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    logging_steps=1,\n",
    "    eval_steps=steps_per_epoch//2,    # 2 evals per epoch\n",
    "    save_steps=steps_per_epoch//100,\n",
    "    save_total_limit=3,     # save once per epoch\n",
    "    gradient_accumulation_steps=ga_steps,\n",
    "    num_train_epochs=epochs,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    optim=\"paged_adamw_32bit\",      # val_loss will go nan with paged_adamw_8bit\n",
    "    learning_rate=lr,\n",
    "    group_by_length=False,\n",
    "    bf16=True,        \n",
    "    ddp_find_unused_parameters=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\src\\transformer-sketchbook\\.venv\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:223: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a88ac7eaa94e7383870818fb390108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/188478 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d8835eade7145539dea8ccb271bd6a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'],\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    args=args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(resume_from_checkpoint=\"../models/phi-2-mlb/checkpoint-1344\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c02783b20a31460aa082f5a2ba7ceccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1472 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\src\\transformer-sketchbook\\.venv\\lib\\site-packages\\torch\\utils\\checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1484, 'learning_rate': 2e-05, 'epoch': 0.0}\n",
      "{'loss': 2.1453, 'learning_rate': 2e-05, 'epoch': 0.0}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\src\\transformer-sketchbook\\.venv\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:323\u001b[0m, in \u001b[0;36mSFTTrainer.train\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trl_activate_neftune(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[1;32m--> 323\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;66;03m# After training we make sure to retrieve back the original forward pass method\u001b[39;00m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;66;03m# for the embedding layer by removing the forward post hook.\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n",
      "File \u001b[1;32me:\\src\\transformer-sketchbook\\.venv\\lib\\site-packages\\transformers\\trainer.py:1561\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1559\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1560\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1562\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\src\\transformer-sketchbook\\.venv\\lib\\site-packages\\transformers\\trainer.py:1895\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1892\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m   1894\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m-> 1895\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1898\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1899\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1900\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1901\u001b[0m ):\n\u001b[0;32m   1902\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1903\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32me:\\src\\transformer-sketchbook\\.venv\\lib\\site-packages\\transformers\\trainer.py:2826\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2824\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m   2825\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2826\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2828\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[1;32me:\\src\\transformer-sketchbook\\.venv\\lib\\site-packages\\accelerate\\accelerator.py:1964\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   1962\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1963\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1964\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\src\\transformer-sketchbook\\.venv\\lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\src\\transformer-sketchbook\\.venv\\lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"../models/phi-2-mlb/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "e:\\src\\transformer-sketchbook\\.venv\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:472: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin e:\\src\\transformer-sketchbook\\.venv\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda121.dll\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0f5e12449e4abbbcfdae0ca629368b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are calling `save_pretrained` to a 4-bit converted model, but your `bitsandbytes` version doesn't support it. If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed.\n",
      "e:\\src\\transformer-sketchbook\\.venv\\lib\\site-packages\\peft\\tuners\\lora\\bnb.py:249: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n",
      "You are calling `save_pretrained` to a 4-bit converted model, but your `bitsandbytes` version doesn't support it. If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The model is quantized with bitsandbytes and is not serializable - check out the warnings from the logger on the traceback to understand the reason why the quantized model is not serializable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m merged_model \u001b[38;5;241m=\u001b[39m PeftModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(model, adapter_path)\n\u001b[0;32m     45\u001b[0m merged_model \u001b[38;5;241m=\u001b[39m merged_model\u001b[38;5;241m.\u001b[39mmerge_and_unload()\n\u001b[1;32m---> 47\u001b[0m \u001b[43mmerged_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_serialization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_shard_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m4GB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39msave_pretrained(save_to)\n\u001b[0;32m     49\u001b[0m generation_config\u001b[38;5;241m.\u001b[39msave_pretrained(save_to)\n",
      "File \u001b[1;32me:\\src\\transformer-sketchbook\\.venv\\lib\\site-packages\\transformers\\modeling_utils.py:2321\u001b[0m, in \u001b[0;36mPreTrainedModel.save_pretrained\u001b[1;34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001b[0m\n\u001b[0;32m   2316\u001b[0m quantization_serializable \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2317\u001b[0m     hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(hf_quantizer, HfQuantizer) \u001b[38;5;129;01mand\u001b[39;00m hf_quantizer\u001b[38;5;241m.\u001b[39mis_serializable\n\u001b[0;32m   2318\u001b[0m )\n\u001b[0;32m   2320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _hf_peft_config_loaded \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quantization_serializable:\n\u001b[1;32m-> 2321\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2322\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model is quantized with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhf_quantizer\u001b[38;5;241m.\u001b[39mquantization_config\u001b[38;5;241m.\u001b[39mquant_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and is not serializable - check out the warnings from\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2323\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m the logger on the traceback to understand the reason why the quantized model is not serializable.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2324\u001b[0m     )\n\u001b[0;32m   2326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_config\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m   2327\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2328\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`save_config` is deprecated and will be removed in v5 of Transformers. Use `is_main_process` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2329\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The model is quantized with bitsandbytes and is not serializable - check out the warnings from the logger on the traceback to understand the reason why the quantized model is not serializable."
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "\n",
    "# base model\n",
    "base_path=\"../models/phi-2\"  \n",
    "\n",
    "# adapters: path to folder with adapter_model.safetensors\n",
    "adapter_path=\"../models/phi-2-mlb/\" \n",
    "\n",
    "# # where to save merged model\n",
    "save_to=\"../models/phi-2-mlb-combined\"       \n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_path, trust_remote_code=True)\n",
    "## Add Special Tokens\n",
    "tokenizer.add_tokens([\"<|im_start|>\", \"<PAD>\"])\n",
    "tokenizer.pad_token = \"<PAD>\"\n",
    "tokenizer.add_special_tokens(dict(eos_token=\"<|im_end|>\"))\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_path, \n",
    "        quantization_config=bnb_config, \n",
    "        device_map = 'auto',\n",
    "        trust_remote_code=True,\n",
    "        use_auth_token=True,\n",
    "    )\n",
    "\n",
    "model.config.eos_token_id = tokenizer.eos_token_id\n",
    "\n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "    max_new_tokens=100, \n",
    "    temperature=0.7,\n",
    "    top_p=0.1,\n",
    "    top_k=40,\n",
    "    repetition_penalty=1.18,\n",
    "    do_sample=True,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "# Load LoRA and merge\n",
    "merged_model = PeftModel.from_pretrained(model, adapter_path)\n",
    "merged_model = merged_model.merge_and_unload()\n",
    "\n",
    "merged_model.save_pretrained(save_to, safe_serialization=True, max_shard_size='4GB')\n",
    "tokenizer.save_pretrained(save_to)\n",
    "generation_config.save_pretrained(save_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a676b4232145d196b7b2aa16e84cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin e:\\src\\transformer-sketchbook\\.venv\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda121.dll\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "\n",
    "# base model\n",
    "base_path=\"../models/phi-2\"  \n",
    "\n",
    "# adapters: path to folder with adapter_model.safetensors\n",
    "adapter_path=\"../models/phi-2-mlb/checkpoint-13100\" \n",
    "      \n",
    "# # Load model and tokenizer\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "if torch.cuda.device_count() > 1: # If more than 1 GPU\n",
    "    base_model.is_parallelizable = False\n",
    "    base_model.model_parallel = False\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_path)\n",
    "\n",
    "# # Add/set tokens same tokens to base model before merging, like we did before training  \n",
    "tokenizer.add_tokens([\"<|im_start|>\", \"<PAD>\"])\n",
    "tokenizer.pad_token = \"<PAD>\"\n",
    "tokenizer.add_special_tokens(dict(eos_token=\"<|im_end|>\"))\n",
    "\n",
    "base_model.config.eos_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Load LoRA and merge\n",
    "merged_model = PeftModel.from_pretrained(base_model, adapter_path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset,DatasetDict\n",
    "dataset = load_dataset(\"json\", data_files='../data/2011_2023_phi-2_struct_encoded.json',field=\"test\", split='all')\n",
    "# dataset = eval_dataset[-1000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_set = []\n",
    "valid_set = []\n",
    "for i in dataset['text']:\n",
    "   split_input = i.split(\"Output: \")\n",
    "   temp = split_input[0]\n",
    "   temp_set.append(f\"{temp}Output: \")\n",
    "   try:\n",
    "      valid = json.loads(split_input[-1])\n",
    "      valid_set.append(valid['event'])\n",
    "   except:\n",
    "      valid = {}\n",
    "      valid_set.append(\"\")\n",
    "      pass\n",
    "   \n",
    "\n",
    "test_set = temp_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Instruct: {\"pitcher\": {\"id\": 444836, \"name\": \"aaron laffey\"}, \"batter\": {\"id\": 475582, \"name\": \"ryan zimmerman\"}, \"at_bat_number\": 53, \"p_throws\": \"L\", \"stand\": \"R\", \"inning_topbot\": \"Top\", \"inning\": 7, \"outs_when_up\": 2, \"on_1b\": {\"id\": \"\", \"name\": \"\"}, \"on_2b\": {\"id\": \"\", \"name\": \"\"}, \"on_3b\": {\"id\": \"\", \"name\": \"\"}, \"home_score\": 2, \"away_score\": 5, \"pitch_number\": 1, \"if_fielding_alignment\": \"\", \"of_fielding_alignment\": \"\"}. \\n Output: '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " {\"event\": \"field_out\", \"event_description\": \"hit_into_play\", \"pitch_name\": \"Sinker\", \"description\": \"Ryan Zimmerman grounds out, second baseman Aaron Miles to first baseman James Loney.\", \"runs\": 0, \"at_bat\": [\"hit_into_play\"], \"release_speeds\": [86.8], \"pitch_names\": [\"Sinker\"]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "input_tokens = tokenizer(test_set[0], return_tensors=\"pt\").to(device)\n",
    "output_tokens = merged_model.generate(**input_tokens, max_new_tokens=512)\n",
    "\n",
    "output = tokenizer.decode(\n",
    "    output_tokens[0][len(input_tokens[0]):],\n",
    "    skip_special_tokens=True\n",
    "    )               \n",
    "\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
