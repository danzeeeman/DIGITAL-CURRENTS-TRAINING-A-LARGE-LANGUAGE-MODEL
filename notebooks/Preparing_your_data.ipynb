{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unidecode\n",
      "  Downloading Unidecode-1.3.7-py3-none-any.whl (235 kB)\n",
      "                                              0.0/235.5 kB ? eta -:--:--\n",
      "                                              0.0/235.5 kB ? eta -:--:--\n",
      "     -                                        10.2/235.5 kB ? eta -:--:--\n",
      "     -                                        10.2/235.5 kB ? eta -:--:--\n",
      "     -                                        10.2/235.5 kB ? eta -:--:--\n",
      "     ----                                  30.7/235.5 kB 262.6 kB/s eta 0:00:01\n",
      "     ------                                41.0/235.5 kB 245.8 kB/s eta 0:00:01\n",
      "     ------------                          81.9/235.5 kB 416.7 kB/s eta 0:00:01\n",
      "     -----------------                    112.6/235.5 kB 504.4 kB/s eta 0:00:01\n",
      "     -------------------------            163.8/235.5 kB 614.4 kB/s eta 0:00:01\n",
      "     ----------------------------------   225.3/235.5 kB 724.0 kB/s eta 0:00:01\n",
      "     ------------------------------------ 235.5/235.5 kB 758.4 kB/s eta 0:00:00\n",
      "Installing collected packages: unidecode\n",
      "Successfully installed unidecode-1.3.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pybaseball import statcast\n",
    "from pybaseball import playerid_reverse_lookup\n",
    "from unidecode import unidecode \n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Data\n",
    "Finding a good data source for training data is very hard.  You need massive amounts of data. One of the approaches is to use derived text to train a specific model.  You can turn statistical data into text by encoding the data with a complex template.  Below I take twenty years of baseball data and encode it into a text format.  This way we use language to represent statistics. \n",
    "\n",
    "We first download and cache all the the mlb statcast events from the start of the season to the end of the season from 2003 to 2023 (this will take a long time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a large query, it may take a moment to complete\n",
      "Skipping offseason dates\n",
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 214/214 [11:16<00:00,  3.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a large query, it may take a moment to complete\n",
      "Skipping offseason dates\n",
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 225/225 [11:46<00:00,  3.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a large query, it may take a moment to complete\n",
      "Skipping offseason dates\n",
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [05:10<00:00,  3.20s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a large query, it may take a moment to complete\n",
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [13:19<00:00,  3.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a large query, it may take a moment to complete\n",
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [13:16<00:00,  3.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a large query, it may take a moment to complete\n",
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [13:29<00:00,  3.29s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "captures = [2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012]\n",
    "years = [2018, 2019, 2020, 2021, 2022, 2023]\n",
    "for year in years:\n",
    "    events = statcast(start_dt=f\"{year}-03-01\", end_dt=f\"{year}-11-15\")\n",
    "    with open(f\"../data/seasons/season-{year}.pickle\", \"wb\") as scores:\n",
    "        pickle.dump(events, scores)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here comes the fun part!  We must examine this data to see what it contains and what we can use to encode the information we want to know.  We want to know the outcome of each pitch to the batter and use that to build a response that contains the at-bat of each player and the subsequent event or the outcome of the at-bat.  \n",
    "\n",
    "But first we use the cache to create a dictionary of the player UUIDs to their actual names\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "season-2003.pickle\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'players' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\src\\transformer-sketchbook\\notebooks\\Preparing_your_data.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/Preparing_your_data.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m batter \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(row\u001b[39m.\u001b[39mbatter)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/Preparing_your_data.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m pitcher \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(row\u001b[39m.\u001b[39mpitcher)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/Preparing_your_data.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mif\u001b[39;00m pitcher \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m players:\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/Preparing_your_data.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     name_data \u001b[39m=\u001b[39m playerid_reverse_lookup([row\u001b[39m.\u001b[39mpitcher], key_type\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmlbam\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/Preparing_your_data.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(name_data[\u001b[39m'\u001b[39m\u001b[39mname_first\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(name_data[\u001b[39m'\u001b[39m\u001b[39mname_last\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'players' is not defined"
     ]
    }
   ],
   "source": [
    "path = \"../data/seasons/\"\n",
    "files = os.listdir(path)\n",
    "files.sort()\n",
    "for file in files:\n",
    "    print(file)\n",
    "    pickle_in = open(f\"{path}/{file}\",\"rb\")\n",
    "    every_pitch = pickle.load(pickle_in)\n",
    "    every_pitch = every_pitch.iloc[::-1]\n",
    "    for index, row in every_pitch.iterrows(): \n",
    "        batter = str(row.batter)\n",
    "        pitcher = str(row.pitcher)\n",
    "        if pitcher not in players:\n",
    "            name_data = playerid_reverse_lookup([row.pitcher], key_type='mlbam')\n",
    "            if len(name_data['name_first']) > 0 and len(name_data['name_last']) > 0:\n",
    "                players[pitcher] = f\"{unidecode(name_data['name_first'][0])} {unidecode(name_data['name_last'][0])}\"\n",
    "            else:\n",
    "                players[pitcher] = pitcher\n",
    "        if batter not in players:\n",
    "            name_data = playerid_reverse_lookup([row.batter], key_type='mlbam')\n",
    "            if len(name_data['name_first']) > 0 and len(name_data['name_last']) > 0:\n",
    "                players[batter] = f\"{unidecode(name_data['name_first'][0])} {unidecode(name_data['name_last'][0])}\"\n",
    "            else:\n",
    "                players[batter] = batter\n",
    "       \n",
    "with open(f'../data/players.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(players, f, ensure_ascii=True, indent=4, allow_nan=True)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../data/players.json', 'r', encoding='utf-8') as f:\n",
    "    players = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "season-2003.pickle\n",
      "season-2004.pickle\n",
      "season-2005.pickle\n",
      "season-2006.pickle\n",
      "season-2007.pickle\n",
      "season-2008.pickle\n",
      "season-2009.pickle\n",
      "season-2010.pickle\n",
      "season-2011.pickle\n",
      "season-2012.pickle\n",
      "season-2014.pickle\n",
      "season-2015.pickle\n",
      "season-2016.pickle\n",
      "season-2018.pickle\n",
      "season-2019.pickle\n",
      "season-2020.pickle\n",
      "season-2021.pickle\n",
      "season-2022.pickle\n",
      "season-2023.pickle\n"
     ]
    }
   ],
   "source": [
    "path = \"../data/seasons/\"\n",
    "files = os.listdir(path)\n",
    "files.sort()\n",
    "baseball = []\n",
    "lines = []\n",
    "test = []\n",
    "season_count = 0\n",
    "for file in files:\n",
    "    print(file)\n",
    "    pickle_in = open(f\"{path}/{file}\",\"rb\")\n",
    "    every_pitch = pickle.load(pickle_in)\n",
    "    every_pitch = every_pitch.iloc[::-1]\n",
    "    season = []\n",
    "    at_bat = []\n",
    "    pre_batter = \"\"\n",
    "    for index, row in every_pitch.iterrows():\n",
    "        current_batter = str(row.batter)\n",
    "        if current_batter not in pre_batter:\n",
    "            at_bat = []\n",
    "        pre_batter = current_batter\n",
    "        if str(row.pitcher) in players and str(row.batter) in players:\n",
    "            instruction = f\"what is the outcome of pitcher {players[str(row.pitcher)]} pitching to batter {players[str(row.batter)]}\" \n",
    "            input_data = f\"{row.inning_topbot} of the {row.inning} inning with {row.outs_when_up} outs \"\n",
    "\n",
    "            description = row.description \n",
    "            description = description.replace(\"_\", \" \")\n",
    "\n",
    "            response = f\"{description} \"\n",
    "            at_bat.append(response)\n",
    "            \n",
    "            if isinstance(row.events, str):\n",
    "                # response = \"\"\n",
    "                event = row.events \n",
    "                event = event.replace(\"_\", \" \")\n",
    "                at_bat.append(event)\n",
    "        \n",
    "                output = \"\"\n",
    "                for pitch in at_bat:\n",
    "                    output =f\"{output}{pitch}\"\n",
    "                score = \"\" if (row.post_bat_score - row.bat_score) < 1 else f\" and {(row.post_bat_score - row.bat_score)} runs scores\"\n",
    "                output = f\"{output}{score}\"                         \n",
    "                baseball.append(\n",
    "                    {\n",
    "                    'instruction':instruction,\n",
    "                    'input':input_data,\n",
    "                    \"output\":output\n",
    "                    }\n",
    "                )\n",
    "                lines.append(f\"<s>###instruction {instruction} ###input {input_data} ###output {output}</s>\\n\") \n",
    "            \n",
    "           \n",
    "    season_count+=1\n",
    "\n",
    "    with open(f'twenty_years_of_baseball_2.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(baseball, f, ensure_ascii=True, indent=4, allow_nan=True)\n",
    "        f.close()\n",
    "\n",
    "with open(f'twenty_years_of_baseball_2.txt', 'w', encoding='utf-8') as f:\n",
    "    f.writelines(lines)\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
