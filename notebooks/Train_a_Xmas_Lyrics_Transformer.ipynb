{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Install Dependencies "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tHOTZYrmevi"
      },
      "outputs": [],
      "source": [
        "!pip install tokenizers\n",
        "!pip install transformers[torch]\n",
        "!pip install accelerate"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### KILL CODE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrNQeVVTsBj6"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# os._exit(00)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CHECK TO MAKE SURE YOU GOT A GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Z0cRlXC-zLX",
        "outputId": "91ab35ee-91db-4683-a738-bb5c2c89c365"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### VERSION CHECK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MszuU-iPr5KG"
      },
      "outputs": [],
      "source": [
        "import accelerate\n",
        "import transformers\n",
        "\n",
        "transformers.__version__, accelerate.__version__"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Connect to GDrive "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets make some folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXbpdMHK_gSG"
      },
      "outputs": [],
      "source": [
        "# !mkdir -p /content/drive/MyDrive/models/xmas/tokenizer"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Converting Your CSV to JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_y717a5f9sER"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import json\n",
        "def convert_csv_to_json(csv_file_path):\n",
        "    # Read CSV file\n",
        "    with open(csv_file_path, 'r') as file:\n",
        "        reader = csv.DictReader(file)\n",
        "        rows = list(reader)\n",
        "\n",
        "    # Convert CSV data to JSON\n",
        "    json_data = json.dumps(rows, indent=4)\n",
        "\n",
        "    # Save JSON data to a file (optional)\n",
        "    with open('../data/All_Playlists_Combined.json', 'w') as json_file:\n",
        "        json_file.write(json_data)\n",
        "\n",
        "    return json_data\n",
        "\n",
        "# Specify the path to your CSV file\n",
        "csv_file_path = '../data/All Playlists Combined.csv'\n",
        "\n",
        "# Convert CSV to JSON\n",
        "json_data = convert_csv_to_json(csv_file_path)\n",
        "\n",
        "print(\"Conversion completed. JSON data:\")\n",
        "print(json_data)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Helper Functions to normalize your data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "R-M63LcMAJEr"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def remove_special_characters_and_spaces(input_string):\n",
        "    # Define a regular expression pattern to match special characters and spaces\n",
        "    pattern = r'[^a-zA-Z0-9]+'  # This pattern will keep only letters and digits\n",
        "\n",
        "    # Use the sub method to replace matches of the pattern with an empty string\n",
        "    clean_string = re.sub(pattern, '', input_string)\n",
        "\n",
        "    return clean_string\n",
        "\n",
        "def remove_special_characters(input_string):\n",
        "    # Define a regular expression pattern to match special characters and spaces\n",
        "    pattern = r'[^a-zA-Z0-9\\s]+'  # This pattern will keep only letters and digits\n",
        "\n",
        "    # Use the sub method to replace matches of the pattern with an empty string\n",
        "    clean_string = re.sub(pattern, '', input_string)\n",
        "\n",
        "    return clean_string"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Proto Prompting "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "cjGs9KzDmKHl"
      },
      "outputs": [],
      "source": [
        "from traitlets import traitlets\n",
        "from dateutil.parser import parse\n",
        "from datetime import datetime\n",
        "import json\n",
        "stats_file = \"../data/All_Playlists_Combined.json\"\n",
        "lines = []\n",
        "with open(stats_file, 'r') as f:\n",
        "    xmas_songs = json.load(f)\n",
        "    for song in xmas_songs:\n",
        "        title = remove_special_characters(song['track_name'])\n",
        "        lyrics = re.sub(r'\\n', ' ', song['lyrics'])\n",
        "        lines.append(f\"<s>##TITLE {title} ###LYRICS {lyrics} </s>\\n\")\n",
        "\n",
        "    with open(f'../data/All_Playlists_Combine.txt', 'w', encoding='utf-8') as f:\n",
        "          f.writelines(lines)\n",
        "          f.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Training a BPE Tokenizer "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kThlA4LpnMLf",
        "outputId": "c1e46d45-0e88-48c2-bda3-c252055f7a5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Sleigh', 'bells', 'ring', 'are', 'you', 'listening']\n"
          ]
        }
      ],
      "source": [
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from pathlib import Path\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "tokenizer = Tokenizer(BPE(unk_token=\"<unk>\"))\n",
        "\n",
        "tokenizer.pre_tokenizer = Whitespace()\n",
        "\n",
        "trainer = BpeTrainer(special_tokens=[\n",
        "    \"<s>\",\n",
        "    \"<pad>\",\n",
        "    \"</s>\",\n",
        "    \"<unk>\",\n",
        "    \"<mask>\"\n",
        "    ])\n",
        "\n",
        "tokenizer.train(files=[\"../data/All_Playlists_Combine.txt\"], trainer=trainer)\n",
        "tokenizer.save(\"../models/xmas/tokenizer.json\")\n",
        "\n",
        "output = tokenizer.encode(\"Sleigh bells ring are you listening\")\n",
        "print(output.tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UnFozzBin_3F"
      },
      "outputs": [],
      "source": [
        "from transformers import RobertaConfig\n",
        "\n",
        "config = RobertaConfig(\n",
        "    vocab_size=12306,\n",
        "    max_position_embeddings=514,\n",
        "    num_attention_heads=12,\n",
        "    num_hidden_layers=6,\n",
        "    type_vocab_size=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "frLPEf9qoCSx"
      },
      "outputs": [],
      "source": [
        "from transformers import RobertaTokenizerFast\n",
        "\n",
        "tokenizer = RobertaTokenizerFast(tokenizer_file=\"../models/xmas/tokenizer.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bQc-nsqoJjO",
        "outputId": "3b9e9f5b-a748-4692-b809-3f5930034250"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "52979730"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import RobertaForMaskedLM\n",
        "\n",
        "model = RobertaForMaskedLM(config=config)\n",
        "model.num_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "DoTD1bX4oOgh"
      },
      "outputs": [],
      "source": [
        "from transformers import LineByLineTextDataset\n",
        "\n",
        "dataset = LineByLineTextDataset(\n",
        "    tokenizer=tokenizer,\n",
        "    file_path=\"../data/All_Playlists_Combine.txt\",\n",
        "    block_size=128,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-2DecShuoSJ9"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "R4-YWjSEoTtY"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"../models/xmas/\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=500,\n",
        "    per_device_train_batch_size=64,\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "    prediction_loss_only=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=dataset,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6SrrqZ2Z6ZO"
      },
      "outputs": [],
      "source": [
        "trainer.train(resume_from_checkpoint='../models/xmas/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTpCxuIMawD8"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(\"../models/xmas/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "lVl9Ix_ePwYz",
        "outputId": "8d64e0d3-a9fe-465e-ed6b-2dc3a4c1c6a8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2000/2000 24:19, Epoch 100/100]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>5.584800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>4.259600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>3.516200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>3.130800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2000, training_loss=4.122851196289062, metrics={'train_runtime': 1460.1922, 'train_samples_per_second': 84.989, 'train_steps_per_second': 1.37, 'total_flos': 4110973722777600.0, 'train_loss': 4.122851196289062, 'epoch': 100.0})"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "id": "6OGytdepobuS",
        "outputId": "561e45fb-d27a-4171-9669-3937cfb99875"
      },
      "outputs": [],
      "source": [
        "trainer.train(resume_from_checkpoint='../models/xmas/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "NR-3iK7Toe--"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(\"../models/xmas/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzK25DHOFlkJ"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "with open(\"../models/xmas/checkpoint-6000/trainer_state.json\", \"r\") as f:\n",
        "  data = json.load(f)\n",
        "\n",
        "  params = {'legend.fontsize': 'small',\n",
        "          'figure.figsize': (15, 10),\n",
        "          'axes.labelsize': 'x-small',\n",
        "          'axes.titlesize':'x-small',\n",
        "          'xtick.labelsize':'x-small',\n",
        "          'ytick.labelsize':'x-small'}\n",
        "  plt.rcParams.update(params)\n",
        "\n",
        "  loss_value = []\n",
        "  for tick in data['log_history']:\n",
        "      if 'loss' in tick:\n",
        "          loss_value.append(tick['loss'])\n",
        "\n",
        "  plt.plot(range(0, len(loss_value)), loss_value, label=f'loss', alpha=0.15)\n",
        "  plt.savefig(f\"../models/xmas/loss.jpg\")\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okBznry4MypI",
        "outputId": "176ef449-b477-4c32-97f7-b0cd833f8952"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "fill_mask = pipeline(\n",
        "    \"fill-mask\",\n",
        "    model=\"../models/xmas/checkpoint-7800\",\n",
        "    tokenizer=tokenizer,\n",
        "    top_k=20,\n",
        ")\n",
        "\n",
        "fill_text = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=\"../models/xmas/checkpoint-7800\",\n",
        "    tokenizer=tokenizer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7cQQNStNMW8"
      },
      "outputs": [],
      "source": [
        "fill_text(\"##TITLE Rockin Around The Christmas Tree ###LYRICS \")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
