{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "1FvTRFr_M-Rx"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2e4fbb7ca28b4cb1a36a70956d5bf900": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6e60b9108954133bd2e8ecda56ad6d3",
              "IPY_MODEL_7af1f59aba964898a7135b478d510496",
              "IPY_MODEL_bc960cae085f4be69dba23721af9693a"
            ],
            "layout": "IPY_MODEL_9e6af875c578463db39a13e1aa632660"
          }
        },
        "c6e60b9108954133bd2e8ecda56ad6d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b23a53ff1f844389f30b4ec6261cb74",
            "placeholder": "​",
            "style": "IPY_MODEL_18c641c751ea44e89a7f1690bbce609b",
            "value": "Downloading (…)olve/main/vocab.json: 100%"
          }
        },
        "7af1f59aba964898a7135b478d510496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32c4c54df15145a9a6aecc13668fb3b0",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_758f35c5c8594738b1e850e67e42d0a2",
            "value": 1042301
          }
        },
        "bc960cae085f4be69dba23721af9693a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89b5e2b570af442b85a206e3a6884fd4",
            "placeholder": "​",
            "style": "IPY_MODEL_8d55dd44fdbc402bb51438ab2b0bc5b0",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 3.93MB/s]"
          }
        },
        "9e6af875c578463db39a13e1aa632660": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b23a53ff1f844389f30b4ec6261cb74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18c641c751ea44e89a7f1690bbce609b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32c4c54df15145a9a6aecc13668fb3b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "758f35c5c8594738b1e850e67e42d0a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89b5e2b570af442b85a206e3a6884fd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d55dd44fdbc402bb51438ab2b0bc5b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8acef38b6df46d38857ffd75d48e39b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_92e60cc655fb4c5dba37712959c7a012",
              "IPY_MODEL_0f4107163914408aad35af19807b04c3",
              "IPY_MODEL_27054784c9fe4c95ab462b9040c95ec0"
            ],
            "layout": "IPY_MODEL_cafaefe07b1b4e99b5a0a52d110dc375"
          }
        },
        "92e60cc655fb4c5dba37712959c7a012": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_804d44c02a1d46ec87ff3ab07d3fe6ce",
            "placeholder": "​",
            "style": "IPY_MODEL_6114fdb6a8564df394a9cdf2b055daba",
            "value": "Downloading (…)olve/main/merges.txt: 100%"
          }
        },
        "0f4107163914408aad35af19807b04c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6665bbf58ad3488d8006b71871861bde",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d6206bb81a74518b1e8caae5887d8b3",
            "value": 456318
          }
        },
        "27054784c9fe4c95ab462b9040c95ec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79e88ea3072449ab83dd246f67d02257",
            "placeholder": "​",
            "style": "IPY_MODEL_d2f8c26a770943798eab00b847e3ca80",
            "value": " 456k/456k [00:00&lt;00:00, 2.25MB/s]"
          }
        },
        "cafaefe07b1b4e99b5a0a52d110dc375": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "804d44c02a1d46ec87ff3ab07d3fe6ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6114fdb6a8564df394a9cdf2b055daba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6665bbf58ad3488d8006b71871861bde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d6206bb81a74518b1e8caae5887d8b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79e88ea3072449ab83dd246f67d02257": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2f8c26a770943798eab00b847e3ca80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27705f0cca0c419aaf371608d38d8863": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ac2d704c4dd4ccf916d2740d8e1fece",
              "IPY_MODEL_0537c48809d940bea760d00a2899ea7a",
              "IPY_MODEL_d11a20bc653b434b93d37ba3759e6783"
            ],
            "layout": "IPY_MODEL_aab7869fdc1846f18f0291ec9df21826"
          }
        },
        "2ac2d704c4dd4ccf916d2740d8e1fece": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4f84595c17a45cd9cf8e21af30bcc98",
            "placeholder": "​",
            "style": "IPY_MODEL_e70e43f069704af28fc9ec0b4a4cdd88",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "0537c48809d940bea760d00a2899ea7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85fc3723276b4882aaddb84ea5649fc8",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d7774409d794c69ae5a28ece0131ae4",
            "value": 665
          }
        },
        "d11a20bc653b434b93d37ba3759e6783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2da52ee9a294477fa57bdb61e01b2e78",
            "placeholder": "​",
            "style": "IPY_MODEL_d1a582e4ad8349b5ba6f0c79f249c3c0",
            "value": " 665/665 [00:00&lt;00:00, 21.6kB/s]"
          }
        },
        "aab7869fdc1846f18f0291ec9df21826": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4f84595c17a45cd9cf8e21af30bcc98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e70e43f069704af28fc9ec0b4a4cdd88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85fc3723276b4882aaddb84ea5649fc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d7774409d794c69ae5a28ece0131ae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2da52ee9a294477fa57bdb61e01b2e78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1a582e4ad8349b5ba6f0c79f249c3c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9c29478b7a2473b9344a5f6b21a0a1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8d65ab8ccaf454585bf041ee42a3a18",
              "IPY_MODEL_34d053c29e184f0d9d945f92054aebc6",
              "IPY_MODEL_e74477cd79364082909ac3c77f86d19a"
            ],
            "layout": "IPY_MODEL_5d3d996db9bb48819219ead7c27c2967"
          }
        },
        "e8d65ab8ccaf454585bf041ee42a3a18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c1fec61e54748408bbe68615a10abe0",
            "placeholder": "​",
            "style": "IPY_MODEL_971878a9aeb14c0fb2c2f088f584a578",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "34d053c29e184f0d9d945f92054aebc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_657dca5059a54df1b4831a7bac53a35e",
            "max": 548118077,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_53e382ecfef742f8b37bdb84f9adf5d0",
            "value": 548118077
          }
        },
        "e74477cd79364082909ac3c77f86d19a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e0e11c8be05424d975bdefcf5ccbeca",
            "placeholder": "​",
            "style": "IPY_MODEL_af26e4e801764b56b6cb003f9772b740",
            "value": " 548M/548M [00:06&lt;00:00, 83.0MB/s]"
          }
        },
        "5d3d996db9bb48819219ead7c27c2967": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c1fec61e54748408bbe68615a10abe0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "971878a9aeb14c0fb2c2f088f584a578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "657dca5059a54df1b4831a7bac53a35e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53e382ecfef742f8b37bdb84f9adf5d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e0e11c8be05424d975bdefcf5ccbeca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af26e4e801764b56b6cb003f9772b740": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ML from Scratch: From attention to transformers\n",
        "\n",
        "* Author: Binxu Wang (binxu_wang@hms.harvard.edu)\n",
        "\n",
        "* Date: Apr.17th, 2023\n"
      ],
      "metadata": {
        "id": "yvBTTFubgJ0i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this first tutorial, we want to dive into the details of attention mechanism. If you are interested, you'd be able to implement self-attention layer and build your own transformer model from scratch.\n",
        "\n",
        "For most established library e.g. `torch`, the code is a bit harder to read, due to efficiency optimization and feature flexibility (numerous `if` `else` path). So here we will develop **a more readable but equivalent model**, and validate it against the offcial implementation."
      ],
      "metadata": {
        "id": "LEyAG_Chgq4B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "1FvTRFr_M-Rx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCs18-JIMx2A"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)"
      ],
      "metadata": {
        "id": "x1754xrzOU4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Self-Attention Mechanism: Single Head"
      ],
      "metadata": {
        "id": "YyAokROySZWa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://raw.githubusercontent.com/Animadversio/TransformerFromScratch/main/media/AttentionSchematics_white-01.png)"
      ],
      "metadata": {
        "id": "2ioS3Nrun62q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embdim = 256\n",
        "headdim = 64\n",
        "tokens = torch.randn(1, 5, embdim) # batch, tokens, embedding\n",
        "Wq = torch.randn(embdim, headdim) / math.sqrt(embdim)\n",
        "Wk = torch.randn(embdim, headdim) / math.sqrt(embdim)\n",
        "Wv = torch.randn(embdim, embdim) / math.sqrt(embdim)"
      ],
      "metadata": {
        "id": "EOsGVI0tNH9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fill in the score matrix computation"
      ],
      "metadata": {
        "id": "Q3GOB0ld4TNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qis = torch.einsum(\"BSE,EH->BSH\", tokens, Wq) # batch x seqlen x headdim\n",
        "kis = torch.einsum(\"BTE,EH->BTH\", tokens, Wk) # batch x seqlen x headdim\n",
        "vis = torch.einsum(\"BTE,EF->BTF\", tokens, Wv) # batch x seqlen x embeddim\n",
        "# Your code here\n",
        "scoremat = torch.einsum(\"BSH,BTH->BST\",qis,kis) # output: batch x seqlen (Query) x seqlen (Key)\n",
        "####\n",
        "attmat = F.softmax(scoremat / math.sqrt(headdim), dim=2)"
      ],
      "metadata": {
        "id": "sGz9Zeh-Orkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some checks to make sure the score correspond to the product of the right pair."
      ],
      "metadata": {
        "id": "l4csHSFhUKCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert(torch.isclose(scoremat[0,1,2], qis[0,1,:]@kis[0,2,:]))\n",
        "assert(torch.isclose(scoremat[0,3,4], qis[0,3,:]@kis[0,4,:]))\n",
        "assert(torch.isclose(scoremat[0,2,2], qis[0,2,:]@kis[0,2,:]))"
      ],
      "metadata": {
        "id": "myg-C-doPKF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zis = torch.einsum(\"BST,BTF->BSF\", attmat, vis)"
      ],
      "metadata": {
        "id": "usrpNpDSQZz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In pytorch, these operations are packed int the function `F.scaled_dot_product_attention`. So let's test our implementation of the single head attention against it."
      ],
      "metadata": {
        "id": "GxiBZ97ZQt1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn_torch = F.scaled_dot_product_attention(qis,kis,vis)\n",
        "assert(torch.allclose(attn_torch, zis, atol=1E-6,rtol=1E-6))"
      ],
      "metadata": {
        "id": "K4FvFf8vPg_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-head attention"
      ],
      "metadata": {
        "id": "cdRNYM5FNIOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embdim = 768\n",
        "headcnt = 12\n",
        "headdim = embdim // headcnt\n",
        "assert headdim * headcnt == embdim\n",
        "tokens = torch.randn(1, 5, embdim) # batch, tokens, embedding\n",
        "Wq = torch.randn(embdim, headcnt * headdim) / math.sqrt(embdim) # heads packed in a single dim\n",
        "Wk = torch.randn(embdim, headcnt * headdim) / math.sqrt(embdim) # heads packed in a single dim\n",
        "Wv = torch.randn(embdim, headcnt * headdim) / math.sqrt(embdim) # heads packed in a single dim"
      ],
      "metadata": {
        "id": "ripFxfj-hjuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch, token_num, _ = tokens.shape\n",
        "qis = torch.einsum(\"BSE,EH->BSH\", tokens, Wq)\n",
        "kis = torch.einsum(\"BTE,EH->BTH\", tokens, Wk)\n",
        "vis = torch.einsum(\"BTE,EH->BTH\", tokens, Wv)\n",
        "# split the single hidden dim into the heads\n",
        "qis_mh = qis.view(batch, token_num, headcnt, headdim)\n",
        "kis_mh = kis.view(batch, token_num, headcnt, headdim)\n",
        "vis_mh = vis.view(batch, token_num, headcnt, headdim)"
      ],
      "metadata": {
        "id": "qN4P4TBZiRHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now your challenge is to compute multihead attention using `einsum`"
      ],
      "metadata": {
        "id": "HXgazGbY4vf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "scoremat_mh = torch.einsum(\"BSHD,BTHD->BHST\",qis_mh,kis_mh)  # Output: batch x headcnt x seqlen (query) x seqlen (key)\n",
        "# End\n",
        "attmat_mh = F.softmax(scoremat_mh / math.sqrt(headdim), dim=-1)\n",
        "zis_mh = torch.einsum(\"BCST,BTCH->BSCH\", attmat_mh, vis_mh)  # batch x seqlen (query) x headcnt x headdim\n",
        "zis = zis_mh.reshape(batch, token_num, headcnt * headdim)"
      ],
      "metadata": {
        "id": "vVGExSq3i-rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's validate the tensor multiplication is correct"
      ],
      "metadata": {
        "id": "kLJo-3CL3BWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# raw attention score of the 1st attention head\n",
        "assert (torch.allclose(scoremat_mh[0, 1], qis_mh[0,:,1] @ kis_mh[0,:,1,:].T))"
      ],
      "metadata": {
        "id": "5yCZ0BI6zLRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokens.shape)\n",
        "print(qis_mh.shape)\n",
        "print(kis_mh.shape)\n",
        "print(vis_mh.shape)\n",
        "print(attmat_mh.shape)\n",
        "print(zis_mh.shape)\n",
        "print(zis.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oy5EBnnetHoU",
        "outputId": "8e020edb-5976-4661-bf86-7e8accd937c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 5, 768])\n",
            "torch.Size([1, 5, 12, 64])\n",
            "torch.Size([1, 5, 12, 64])\n",
            "torch.Size([1, 5, 12, 64])\n",
            "torch.Size([1, 12, 5, 5])\n",
            "torch.Size([1, 5, 12, 64])\n",
            "torch.Size([1, 5, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In `torch` this operation is packed in `nn.MultiheadAttention`, including the input projection, attention and out projection. So, note the input the the `mha.forward` function are the *token_embeddings* not the Q,K,Vs as we put it in `F.scaled_dot_product_attention`"
      ],
      "metadata": {
        "id": "gr5UOaYo1Rtf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mha = nn.MultiheadAttention(embdim, headcnt, batch_first=True,)\n",
        "print(mha.in_proj_weight.shape) # 3 * embdim x embdim\n",
        "mha.in_proj_weight.data = torch.cat([Wq, Wk, Wv], dim=1).T"
      ],
      "metadata": {
        "id": "apQhwC6nU5Uy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfde7080-a5d6-431e-c9be-3d3b6ee822d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2304, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_out, attn_weights = mha(tokens, tokens, tokens, average_attn_weights=False,)\n",
        "assert torch.allclose(attmat_mh, attn_weights, atol=1e-6, rtol=1e-6)"
      ],
      "metadata": {
        "id": "YQcH-49V0Pyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In `nn.MultiheadAttention` , there is a output projection `out_proj`, projecting the values. It is a linear layer with bias. We can validate that going through this projection our outputs `zis` is the same as the output of `mha`"
      ],
      "metadata": {
        "id": "ukm63wFj0WC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(mha.out_proj)\n",
        "assert torch.allclose(attn_out, mha.out_proj(zis), atol=1e-6, rtol=1e-6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ci12a8np0VQH",
        "outputId": "a9f7514d-9298-494c-f54c-91bae453f3a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Causal attention mask\n",
        "\n",
        "For models such as GPT, each token can only attend to tokens before it, thus the attention score needs to be modified before entering softmax.\n",
        "\n",
        "The common way of masking is to add a large negative number to the locations that you'd not want the model to attend to."
      ],
      "metadata": {
        "id": "Da0lDydB3zoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn_mask = torch.ones(token_num,token_num,)\n",
        "attn_mask = -1E4 * torch.triu(attn_mask,1)\n",
        "attn_mask"
      ],
      "metadata": {
        "id": "8s_xVQiN4TNf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dce0ca39-234b-41e9-e5b2-139dbf86cb52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[    -0., -10000., -10000., -10000., -10000.],\n",
              "        [    -0.,     -0., -10000., -10000., -10000.],\n",
              "        [    -0.,     -0.,     -0., -10000., -10000.],\n",
              "        [    -0.,     -0.,     -0.,     -0., -10000.],\n",
              "        [    -0.,     -0.,     -0.,     -0.,     -0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scoremat_mh_msk = torch.einsum(\"BSCH,BTCH->BCST\", qis_mh, kis_mh)  # batch x headcnt x seqlen (query) x seqlen (key)\n",
        "scoremat_mh_msk += attn_mask  # add the attn mask to the scores before SoftMax normalization\n",
        "attmat_mh_msk = F.softmax(scoremat_mh_msk / math.sqrt(headdim), dim=-1)\n",
        "zis_mh_msk = torch.einsum(\"BCST,BTCH->BSCH\", attmat_mh_msk, vis_mh)  # batch x seqlen (query) x headcnt x headdim\n",
        "# zis_mh = torch.einsum(\"BSCT,BTCH->BSCH\", attmat_mh, vis_mh)\n",
        "zis_msk = zis_mh_msk.reshape(batch, token_num, headcnt * headdim)"
      ],
      "metadata": {
        "id": "IXbr6nVQ4L2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note** `is_causal` parameter should work and create a causal mask automatically. But in a recent pytorch bug, it doesn't work. So beware~\n",
        "https://github.com/pytorch/pytorch/issues/99282"
      ],
      "metadata": {
        "id": "Es5ABKzQ5phg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn_out_causal, attn_weights_causal = mha(tokens, tokens, tokens, average_attn_weights=False, attn_mask=attn_mask)"
      ],
      "metadata": {
        "id": "ySFCHtmE46QA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert torch.allclose(attn_weights_causal, attmat_mh_msk, atol=1e-6, rtol=1e-6)\n",
        "assert torch.allclose(attn_out_causal, mha.out_proj(zis_msk), atol=1e-6, rtol=1e-6)"
      ],
      "metadata": {
        "id": "Fcmb5yX16buH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "for head in range(headcnt):\n",
        "    plt.subplot(3, 4, head + 1)\n",
        "    plt.imshow(attn_weights_causal[0, head].detach().numpy())\n",
        "    plt.title(f\"head {head}\")\n",
        "    plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kHUZgGm74_qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer Block"
      ],
      "metadata": {
        "id": "3JuaP78yWMva"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Having gaining some intuition about attention layer, let's build it into a transformer. An vanilla transformer block usually looks like this. Note there are slight difference between the transformer blocks in GPT2, BERT and other models, but they generally has the following components\n",
        "\n",
        "* Transformer Block\n",
        "  * Layernorm\n",
        "  * Skip connections\n",
        "  * Multi-head attention\n",
        "  * MLP, Feedforward net\n"
      ],
      "metadata": {
        "id": "BqscmIG11NDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock_simple(nn.Module):\n",
        "\n",
        "    def __init__(self, embdim, headcnt, *args, dropout=0.0, **kwargs) -> None:\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.ln1 = nn.LayerNorm(embdim)\n",
        "        self.ln2 = nn.LayerNorm(embdim)\n",
        "        self.attn = nn.MultiheadAttention(embdim, headcnt, batch_first=True,)\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(embdim, 4 * embdim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(4 * embdim, embdim),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, is_causal=True):\n",
        "        batch, token_num, hidden_dim = x.shape\n",
        "        if is_causal:\n",
        "            attn_mask = torch.ones(token_num, token_num,)\n",
        "            attn_mask = -1E4 * torch.triu(attn_mask,1)\n",
        "        else:\n",
        "            attn_mask = None\n",
        "\n",
        "        residue = x\n",
        "        x = self.ln1(x)\n",
        "        attn_output, attn_weights = self.attn(x, x, x, attn_mask=attn_mask)  # first output is the output latent states\n",
        "        x = residue + attn_output\n",
        "\n",
        "        residue = x\n",
        "        x = self.ln2(x)\n",
        "        ffn_output = self.ffn(x)\n",
        "        output = residue + ffn_output\n",
        "        return output"
      ],
      "metadata": {
        "id": "zZBi1l6-WMTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare the implmentation with the schematics and see if it makes more sense!\n",
        "\n",
        "\n",
        "**BERT**\n",
        "\n",
        "![BERT (Transformer encoder)](https://iq.opengenus.org/content/images/2020/06/encoder-1.png)\n",
        "\n",
        "**GPT2**\n",
        "\n",
        "![](https://miro.medium.com/v2/1*jbcwhhB8PEpJRk781rML_g.png)"
      ],
      "metadata": {
        "id": "xbR05_AZUl78"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example: GPT2 from `Transformers` library"
      ],
      "metadata": {
        "id": "IOTZcdaQVASY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ih7EtU3GVCnt",
        "outputId": "c85f980f-2d81-498a-f9f4-39f0feba5351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers[torch]\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers[torch]) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers[torch]) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers[torch]) (23.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers[torch]) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers[torch]) (3.11.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers[torch]) (2.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers[torch]) (1.22.4)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.9 in /usr/local/lib/python3.9/dist-packages (from transformers[torch]) (2.0.0+cu118)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers[torch]) (4.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (1.11.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (2.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]) (16.0.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers[torch]) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers[torch]) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers[torch]) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers[torch]) (2022.12.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch!=1.12.0,>=1.9->transformers[torch]) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch!=1.12.0,>=1.9->transformers[torch]) (1.3.0)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.4 tokenizers-0.13.3 transformers-4.28.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Printing utils\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "def recursive_print(module, prefix=\"\", depth=0, deepest=3):\n",
        "    \"\"\"Simulating print(module) for torch.nn.Modules\n",
        "        but with depth control. Print to the `deepest` level. `deepest=0` means no print\n",
        "    \"\"\"\n",
        "    if depth == 0:\n",
        "        print(f\"[{type(module).__name__}]\")\n",
        "    if depth >= deepest:\n",
        "        return\n",
        "    for name, child in module.named_children():\n",
        "        if len([*child.named_children()]) == 0:\n",
        "            print(f\"{prefix}({name}): {child}\")\n",
        "        else:\n",
        "            if isinstance(child, nn.ModuleList):\n",
        "                print(f\"{prefix}({name}): {type(child).__name__} len={len(child)}\")\n",
        "            else:\n",
        "                print(f\"{prefix}({name}): {type(child).__name__}\")\n",
        "        recursive_print(child, prefix + \"  \", depth + 1, deepest)"
      ],
      "metadata": {
        "id": "3BPlsjfWH-Ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2Model\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = GPT2Model.from_pretrained(\"gpt2\")\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561,
          "referenced_widgets": [
            "2e4fbb7ca28b4cb1a36a70956d5bf900",
            "c6e60b9108954133bd2e8ecda56ad6d3",
            "7af1f59aba964898a7135b478d510496",
            "bc960cae085f4be69dba23721af9693a",
            "9e6af875c578463db39a13e1aa632660",
            "8b23a53ff1f844389f30b4ec6261cb74",
            "18c641c751ea44e89a7f1690bbce609b",
            "32c4c54df15145a9a6aecc13668fb3b0",
            "758f35c5c8594738b1e850e67e42d0a2",
            "89b5e2b570af442b85a206e3a6884fd4",
            "8d55dd44fdbc402bb51438ab2b0bc5b0",
            "e8acef38b6df46d38857ffd75d48e39b",
            "92e60cc655fb4c5dba37712959c7a012",
            "0f4107163914408aad35af19807b04c3",
            "27054784c9fe4c95ab462b9040c95ec0",
            "cafaefe07b1b4e99b5a0a52d110dc375",
            "804d44c02a1d46ec87ff3ab07d3fe6ce",
            "6114fdb6a8564df394a9cdf2b055daba",
            "6665bbf58ad3488d8006b71871861bde",
            "5d6206bb81a74518b1e8caae5887d8b3",
            "79e88ea3072449ab83dd246f67d02257",
            "d2f8c26a770943798eab00b847e3ca80",
            "27705f0cca0c419aaf371608d38d8863",
            "2ac2d704c4dd4ccf916d2740d8e1fece",
            "0537c48809d940bea760d00a2899ea7a",
            "d11a20bc653b434b93d37ba3759e6783",
            "aab7869fdc1846f18f0291ec9df21826",
            "d4f84595c17a45cd9cf8e21af30bcc98",
            "e70e43f069704af28fc9ec0b4a4cdd88",
            "85fc3723276b4882aaddb84ea5649fc8",
            "7d7774409d794c69ae5a28ece0131ae4",
            "2da52ee9a294477fa57bdb61e01b2e78",
            "d1a582e4ad8349b5ba6f0c79f249c3c0",
            "a9c29478b7a2473b9344a5f6b21a0a1c",
            "e8d65ab8ccaf454585bf041ee42a3a18",
            "34d053c29e184f0d9d945f92054aebc6",
            "e74477cd79364082909ac3c77f86d19a",
            "5d3d996db9bb48819219ead7c27c2967",
            "7c1fec61e54748408bbe68615a10abe0",
            "971878a9aeb14c0fb2c2f088f584a578",
            "657dca5059a54df1b4831a7bac53a35e",
            "53e382ecfef742f8b37bdb84f9adf5d0",
            "8e0e11c8be05424d975bdefcf5ccbeca",
            "af26e4e801764b56b6cb003f9772b740"
          ]
        },
        "id": "3JeilpFDbB5P",
        "outputId": "02082be3-4f17-4d0b-b931-5d4cb77f17d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e4fbb7ca28b4cb1a36a70956d5bf900"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8acef38b6df46d38857ffd75d48e39b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "27705f0cca0c419aaf371608d38d8863"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9c29478b7a2473b9344a5f6b21a0a1c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2Model(\n",
              "  (wte): Embedding(50257, 768)\n",
              "  (wpe): Embedding(1024, 768)\n",
              "  (drop): Dropout(p=0.1, inplace=False)\n",
              "  (h): ModuleList(\n",
              "    (0-11): 12 x GPT2Block(\n",
              "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): GPT2Attention(\n",
              "        (c_attn): Conv1D()\n",
              "        (c_proj): Conv1D()\n",
              "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (mlp): GPT2MLP(\n",
              "        (c_fc): Conv1D()\n",
              "        (c_proj): Conv1D()\n",
              "        (act): NewGELUActivation()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's first look at the general architecture of GPT2 (small), it's actually simple and elegant.\n",
        "* `wte` token embedding\n",
        "* `wpe` position embedding\n",
        "* `h` sequence of Transformer blocks\n",
        "* `LayerNorm` final normalization"
      ],
      "metadata": {
        "id": "7DjdGVciFQOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recursive_print(model, deepest=2)"
      ],
      "metadata": {
        "id": "gmm35lkvbl28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67e40ca5-3290-4626-af7c-d8c350807c9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GPT2Model]\n",
            "(wte): Embedding(50257, 768)\n",
            "(wpe): Embedding(1024, 768)\n",
            "(drop): Dropout(p=0.1, inplace=False)\n",
            "(h): ModuleList len=12\n",
            "  (0): GPT2Block\n",
            "  (1): GPT2Block\n",
            "  (2): GPT2Block\n",
            "  (3): GPT2Block\n",
            "  (4): GPT2Block\n",
            "  (5): GPT2Block\n",
            "  (6): GPT2Block\n",
            "  (7): GPT2Block\n",
            "  (8): GPT2Block\n",
            "  (9): GPT2Block\n",
            "  (10): GPT2Block\n",
            "  (11): GPT2Block\n",
            "(ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Within each GPT2block, you can see the similarity with our model"
      ],
      "metadata": {
        "id": "o4q3zAKeFs2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recursive_print(model.h[0], deepest=2)"
      ],
      "metadata": {
        "id": "KmlaUORNFLi-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbd3aeba-413b-4128-f693-e7b719f9b4b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GPT2Block]\n",
            "(ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "(attn): GPT2Attention\n",
            "  (c_attn): Conv1D()\n",
            "  (c_proj): Conv1D()\n",
            "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "(ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "(mlp): GPT2MLP\n",
            "  (c_fc): Conv1D()\n",
            "  (c_proj): Conv1D()\n",
            "  (act): NewGELUActivation()\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPT in action"
      ],
      "metadata": {
        "id": "VxtcMNbqOavV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\"I have a cat, her name is\", return_tensors=\"pt\")\n",
        "outputs = model(**inputs, output_attentions=True, output_hidden_states=True)"
      ],
      "metadata": {
        "id": "z3zIEHZpD-BH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tokens model reads are the following"
      ],
      "metadata": {
        "id": "PpRNpcUZJTXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_strs = tokenizer.tokenize(\"I have a cat, her name is\")\n",
        "print(token_strs)\n",
        "token_strs = [tok.replace(\"Ġ\",\"\") for tok in token_strs]"
      ],
      "metadata": {
        "id": "4EAbfizAI799",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b73c9ead-c95f-405b-9ac7-74b3c982ab92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'Ġhave', 'Ġa', 'Ġcat', ',', 'Ġher', 'Ġname', 'Ġis']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of final output token vectors\", outputs.last_hidden_state.shape)\n",
        "# attention of each GPTBlock:\n",
        "print(\"num of attention outputs\", len(outputs.attentions))\n",
        "# shape of each attention tensor: [batch, heads, token (source), token (target)]\n",
        "print(\"shape of each attention tensor\", outputs.attentions[-1].shape)\n",
        "print(\"num of hidden states (input embed included.) \", len(outputs.hidden_states))\n",
        "print(\"shape of each hidden states tensor\", outputs.hidden_states[-1].shape) #[batch, token, hidden]\n",
        "assert torch.allclose(outputs.hidden_states[-1], outputs.last_hidden_state)"
      ],
      "metadata": {
        "id": "PRO5hXWYGmAV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4d0edbc-8354-42d4-effa-a7f4d6434aab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of final output token vectors torch.Size([1, 8, 768])\n",
            "num of attention outputs 12\n",
            "shape of each attention tensor torch.Size([1, 12, 8, 8])\n",
            "num of hidden states (input embed included.)  13\n",
            "shape of each hidden states tensor torch.Size([1, 8, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Visualizaing attention\n",
        "for layeri in range(12):\n",
        "    plt.figure(figsize=(13, 8))\n",
        "    for head in range(12):\n",
        "        plt.subplot(3, 4, head + 1)\n",
        "        plt.imshow(outputs.attentions[layeri][0, head, :, :].detach().numpy())\n",
        "        plt.yticks(range(len(token_strs)), token_strs)\n",
        "        plt.xticks(range(len(token_strs)), token_strs)\n",
        "    plt.suptitle(f\"Layer {layeri} attention per head\",fontsize=14)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "g49rGDCjJ2dR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra Credit: GPT2 from scratch\n",
        "\n",
        "If you feel ambitious, you can build a GPT2 from scratch using all the building blocks we have."
      ],
      "metadata": {
        "id": "NRh3POyYPMJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Weight transfer utils\n",
        "from transformers.activations import NewGELUActivation\n",
        "\n",
        "def GPT2block_to_TransformerBlock_simple(tfmblock, gpt2block, ):\n",
        "    \"\"\"copy the weights from a GPT2 block to a TransformerBlock_simple\"\"\"\n",
        "    tfmblock.ln1.weight.data = gpt2block.ln_1.weight\n",
        "    tfmblock.ln1.bias.data = gpt2block.ln_1.bias\n",
        "    tfmblock.ln2.weight.data = gpt2block.ln_2.weight\n",
        "    tfmblock.ln2.bias.data = gpt2block.ln_2.bias\n",
        "    tfmblock.attn.in_proj_weight.data = gpt2block.attn.c_attn.weight.T\n",
        "    tfmblock.attn.in_proj_bias.data = gpt2block.attn.c_attn.bias\n",
        "    tfmblock.attn.out_proj.weight.data = gpt2block.attn.c_proj.weight.T\n",
        "    tfmblock.attn.out_proj.bias.data = gpt2block.attn.c_proj.bias\n",
        "    tfmblock.ffn[0].weight.data = gpt2block.mlp.c_fc.weight.T\n",
        "    tfmblock.ffn[0].bias.data = gpt2block.mlp.c_fc.bias\n",
        "    tfmblock.ffn[1] = NewGELUActivation()\n",
        "    # mlp in GPT2 and BERT used a new GELU activation, using nn.GeLU() will cause a small error around 1E-3\n",
        "    tfmblock.ffn[2].weight.data = gpt2block.mlp.c_proj.weight.T\n",
        "    tfmblock.ffn[2].bias.data = gpt2block.mlp.c_proj.bias\n",
        "    return tfmblock"
      ],
      "metadata": {
        "id": "ItTlhIUCQcgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test if our implementation of model is the same as the transformer block"
      ],
      "metadata": {
        "id": "t6amdmPJR8cE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embdim = 768\n",
        "headcnt = 12\n",
        "tfmblock = TransformerBlock_simple(embdim, headcnt)\n",
        "GPT2block_to_TransformerBlock_simple(tfmblock, model.h[0])\n",
        "\n",
        "tokens_embs = torch.randn(2, 5, 768)\n",
        "tfmblock_out = tfmblock(tokens_embs, is_causal=True)\n",
        "modelblock_out, = model.h[0](tokens_embs)\n",
        "assert torch.allclose(tfmblock_out, modelblock_out, atol=1e-5, rtol=1e-5)"
      ],
      "metadata": {
        "id": "oV3CMx9HRmcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "734f5278-6a1f-43d9-fcdc-b8c91cce516a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-896c5f69fa72>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0membdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mheadcnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtfmblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformerBlock_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheadcnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mGPT2block_to_TransformerBlock_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfmblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'TransformerBlock_simple' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define a simple GPT2"
      ],
      "metadata": {
        "id": "WVUD8tLRShhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT2Model_simple(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.wte = nn.Embedding(50257, 768)\n",
        "        self.wpe = nn.Embedding(1024, 768)\n",
        "        self.blocks = nn.ModuleList([TransformerBlock_simple(768, 12) for _ in range(12)])\n",
        "        self.ln_f = nn.LayerNorm(768)\n",
        "\n",
        "    def forward(self, input_ids, input_embeds=None, is_causal=True):\n",
        "        embeds = self.wte(input_ids) if input_embeds is None else input_embeds\n",
        "        embeds = embeds + self.wpe(torch.arange(embeds.shape[1], device=embeds.device))\n",
        "        for block in self.blocks:\n",
        "            embeds = block(embeds, is_causal=is_causal)\n",
        "        return self.ln_f(embeds)\n"
      ],
      "metadata": {
        "id": "TNdg1JBMSkOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Weight transport utils\n",
        "def GPT2Model_to_GPT2Model_simple(gpt2modelsimple, gpt2model, ):\n",
        "    \"\"\"copy the weights from a GPT2 model to a GPT2Model_simple\"\"\"\n",
        "    gpt2modelsimple.wte.weight.data = gpt2model.wte.weight\n",
        "    gpt2modelsimple.wpe.weight.data = gpt2model.wpe.weight\n",
        "    gpt2modelsimple.ln_f.weight.data = gpt2model.ln_f.weight\n",
        "    gpt2modelsimple.ln_f.bias.data = gpt2model.ln_f.bias\n",
        "    for i in range(12):\n",
        "        GPT2block_to_TransformerBlock_simple(gpt2modelsimple.blocks[i], gpt2model.h[i])\n",
        "    return gpt2modelsimple"
      ],
      "metadata": {
        "cellView": "form",
        "id": "O-NgWzwGSvXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ours = GPT2Model_simple()\n",
        "GPT2Model_to_GPT2Model_simple(model_ours, model)"
      ],
      "metadata": {
        "id": "XPDr2AeIQkhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\"I have a cat, her name is\", return_tensors=\"pt\")\n",
        "outputs = model(**inputs, )"
      ],
      "metadata": {
        "id": "IBh9uMpZTLpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_last_ours = model_ours(inputs['input_ids'])"
      ],
      "metadata": {
        "id": "Z2VR3ZKhTYpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert torch.allclose(outputs.last_hidden_state, hidden_last_ours, atol=1e-5, rtol=1e-5)"
      ],
      "metadata": {
        "id": "miLGwamUTgc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Congrats on finishing this journey of building your own GPT!\n",
        "\n",
        "Now, let the GPU roar and train the transformer!"
      ],
      "metadata": {
        "id": "Z0Y6UqK7U4wU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What's next\n",
        "**Transformer Tutorial Series**\n",
        "* Fundamentals\n",
        "  * [Understanding Attention & Transformer](https://colab.research.google.com/drive/1ZuhA6khlWm57WGZ8i38JH-gc5aJrvpvs?usp=sharing)\n",
        "  * [Language modelling](https://colab.research.google.com/drive/1zZYzAopL__LW4glruSF9lnZYlEmSVI8j?usp=sharing)\n",
        "* Beyond Language\n",
        "  * [Learn to do arithmetics by sequence modelling.](https://colab.research.google.com/drive/1vO71-o-8-3IrOe44Ha0nsHmUsEGVSC37?usp=sharing)\n",
        "  * [Image generation by sequence modelling.](https://colab.research.google.com/drive/1UHlEbepqdvk68cYV1fvkmWl2TBKXfm8E?usp=sharing)\n",
        "  * [Audio signal classification](https://colab.research.google.com/drive/1O4XHOJyOu3_lyaPHAKJM_XTztrAb7VFP?usp=sharing) (~ 20 min)\n",
        "  * [Image classification](https://colab.research.google.com/drive/1JDQQlLMGzo675AfrtkFn1kbuADtVemJz?usp=sharing) (~ 30 min)\n",
        "  * [Music generation by sequence modelling.](https://colab.research.google.com/drive/14zpzLpR4UBIzEQmeaXlMv_mDFYIv3Vht?usp=sharing) (Difficult, training takes hrs)\n",
        "* Using Large Language Model\n",
        "  * [OpenAI API and Chat with PDF](https://colab.research.google.com/drive/19mYEyavBhOnAbEQJQuztXAxWxyYbsQzi?usp=sharing)\n"
      ],
      "metadata": {
        "id": "N-6LDHtBqfuu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### See also\n",
        "* Code tutorial https://nn.labml.ai/transformers/index.html\n",
        "\n"
      ],
      "metadata": {
        "id": "ZpTc2pkyEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reference: GPT2 source code in huggingface implementation"
      ],
      "metadata": {
        "id": "qavZE0UXfDmO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are interested, we also copied the code of GPT2 within transformer library here for your review."
      ],
      "metadata": {
        "id": "oQ99CUa0gUSL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation of a single GPT block (repetition unit of GPT)\n",
        "```python\n",
        "class GPT2Block(nn.Module):\n",
        "    def __init__(self, config, layer_idx=None):\n",
        "        super().__init__()\n",
        "        hidden_size = config.hidden_size\n",
        "        inner_dim = config.n_inner if config.n_inner is not None else 4 * hidden_size\n",
        "\n",
        "        self.ln_1 = nn.LayerNorm(hidden_size, eps=config.layer_norm_epsilon)\n",
        "        self.attn = GPT2Attention(config, layer_idx=layer_idx)\n",
        "        self.ln_2 = nn.LayerNorm(hidden_size, eps=config.layer_norm_epsilon)\n",
        "\n",
        "        if config.add_cross_attention:\n",
        "            # attention to encoder stuff\n",
        "            self.crossattention = GPT2Attention(config,\n",
        "            self.ln_cross_attn = nn.LayerNorm(hidden_size, eps=config.layer_norm_epsilon)\n",
        "\n",
        "        self.mlp = GPT2MLP(inner_dim, config)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: Optional[Tuple[torch.FloatTensor]],\n",
        "        layer_past: Optional[Tuple[torch.Tensor]] = None,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        use_cache: Optional[bool] = False,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Union[Tuple[torch.Tensor], Optional[Tuple[torch.Tensor, Tuple[torch.FloatTensor, ...]]]]:\n",
        "        residual = hidden_states\n",
        "        hidden_states = self.ln_1(hidden_states) # layernorm 1\n",
        "        attn_outputs = self.attn(\n",
        "            hidden_states,\n",
        "            layer_past=layer_past,\n",
        "            attention_mask=attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            use_cache=use_cache,\n",
        "            output_attentions=output_attentions,\n",
        "        )  # attention\n",
        "        attn_output = attn_outputs[0]  # output_attn: a, present, (attentions)\n",
        "        outputs = attn_outputs[1:]\n",
        "        # residual connection\n",
        "        hidden_states = attn_output + residual\n",
        "\n",
        "        if encoder_hidden_states is not None:\n",
        "            # add one self-attention block for cross-attention\n",
        "            if not hasattr(self, \"crossattention\"):\n",
        "                raise ValueError(\n",
        "                    f\"If `encoder_hidden_states` are passed, {self} has to be instantiated with \"\n",
        "                    \"cross-attention layers by setting `config.add_cross_attention=True`\"\n",
        "                )\n",
        "            residual = hidden_states\n",
        "            hidden_states = self.ln_cross_attn(hidden_states)\n",
        "            cross_attn_outputs = self.crossattention(\n",
        "                hidden_states,\n",
        "                attention_mask=attention_mask,\n",
        "                head_mask=head_mask,\n",
        "                encoder_hidden_states=encoder_hidden_states,\n",
        "                encoder_attention_mask=encoder_attention_mask,\n",
        "                output_attentions=output_attentions,\n",
        "            )\n",
        "            attn_output = cross_attn_outputs[0]\n",
        "            # residual connection\n",
        "            hidden_states = residual + attn_output\n",
        "            outputs = outputs + cross_attn_outputs[2:]  # add cross attentions if we output attention weights\n",
        "\n",
        "        residual = hidden_states\n",
        "        hidden_states = self.ln_2(hidden_states) # apply ln2 after adding attention processing.\n",
        "        feed_forward_hidden_states = self.mlp(hidden_states) # mlp process the hidden state\n",
        "        # residual connection\n",
        "        hidden_states = residual + feed_forward_hidden_states\n",
        "\n",
        "        if use_cache:\n",
        "            outputs = (hidden_states,) + outputs\n",
        "        else:\n",
        "            outputs = (hidden_states,) + outputs[1:]\n",
        "\n",
        "        return outputs  # hidden_states, present, (attentions, cross_attentions)\n",
        "```"
      ],
      "metadata": {
        "id": "CsLekntcb71g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom designed Conv1D layer in huggingface (basically a linear layer)\n",
        "```python\n",
        "class Conv1D(nn.Module):\n",
        "    \"\"\"\n",
        "    1D-convolutional layer as defined by Radford et al. for OpenAI GPT (and also used in GPT-2).\n",
        "    Basically works like a linear layer but the weights are transposed.\n",
        "    Args:\n",
        "        nf (`int`): The number of output features.\n",
        "        nx (`int`): The number of input features.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, nf, nx):\n",
        "        super().__init__()\n",
        "        self.nf = nf\n",
        "        w = torch.empty(nx, nf)\n",
        "        nn.init.normal_(w, std=0.02)\n",
        "        self.weight = nn.Parameter(w)\n",
        "        self.bias = nn.Parameter(torch.zeros(nf))\n",
        "\n",
        "    def forward(self, x):\n",
        "        size_out = x.size()[:-1] + (self.nf,)\n",
        "        x = torch.addmm(self.bias, x.view(-1, x.size(-1)), self.weight)\n",
        "        x = x.view(size_out)\n",
        "        return x\n",
        "```"
      ],
      "metadata": {
        "id": "SYerj8MHe63e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attention mechanism implemented in GPT2\n",
        "```python\n",
        "class GPT2Attention(nn.Module):\n",
        "    def __init__(self, config, is_cross_attention=False, layer_idx=None):\n",
        "        super().__init__()\n",
        "\n",
        "        max_positions = config.max_position_embeddings\n",
        "        self.register_buffer(\n",
        "            \"bias\",\n",
        "            torch.tril(torch.ones((max_positions, max_positions), dtype=torch.uint8)).view(\n",
        "                1, 1, max_positions, max_positions\n",
        "            ),\n",
        "        )\n",
        "        self.register_buffer(\"masked_bias\", torch.tensor(-1e4))\n",
        "\n",
        "        self.embed_dim = config.hidden_size\n",
        "        self.num_heads = config.num_attention_heads\n",
        "        self.head_dim = self.embed_dim // self.num_heads\n",
        "        self.split_size = self.embed_dim\n",
        "        if self.head_dim * self.num_heads != self.embed_dim:\n",
        "            raise ValueError(\n",
        "                f\"`embed_dim` must be divisible by num_heads (got `embed_dim`: {self.embed_dim} and `num_heads`:\"\n",
        "                f\" {self.num_heads}).\"\n",
        "            )\n",
        "\n",
        "        self.scale_attn_weights = config.scale_attn_weights\n",
        "        self.is_cross_attention = is_cross_attention\n",
        "\n",
        "        # Layer-wise attention scaling, reordering, and upcasting\n",
        "        self.scale_attn_by_inverse_layer_idx = config.scale_attn_by_inverse_layer_idx\n",
        "        self.layer_idx = layer_idx\n",
        "        self.reorder_and_upcast_attn = config.reorder_and_upcast_attn\n",
        "\n",
        "        if self.is_cross_attention:\n",
        "            self.c_attn = Conv1D(2 * self.embed_dim, self.embed_dim)\n",
        "            self.q_attn = Conv1D(self.embed_dim, self.embed_dim)\n",
        "        else:\n",
        "            self.c_attn = Conv1D(3 * self.embed_dim, self.embed_dim)\n",
        "        self.c_proj = Conv1D(self.embed_dim, self.embed_dim)\n",
        "\n",
        "        self.attn_dropout = nn.Dropout(config.attn_pdrop)\n",
        "        self.resid_dropout = nn.Dropout(config.resid_pdrop)\n",
        "\n",
        "        self.pruned_heads = set()\n",
        "\n",
        "    def prune_heads(self, heads):\n",
        "        if len(heads) == 0:\n",
        "            return\n",
        "        heads, index = find_pruneable_heads_and_indices(heads, self.num_heads, self.head_dim, self.pruned_heads)\n",
        "        index_attn = torch.cat([index, index + self.split_size, index + (2 * self.split_size)])\n",
        "\n",
        "        # Prune conv1d layers\n",
        "        self.c_attn = prune_conv1d_layer(self.c_attn, index_attn, dim=1)\n",
        "        self.c_proj = prune_conv1d_layer(self.c_proj, index, dim=0)\n",
        "\n",
        "        # Update hyper params\n",
        "        self.split_size = (self.split_size // self.num_heads) * (self.num_heads - len(heads))\n",
        "        self.num_heads = self.num_heads - len(heads)\n",
        "        self.pruned_heads = self.pruned_heads.union(heads)\n",
        "\n",
        "    def _attn(self, query, key, value, attention_mask=None, head_mask=None):\n",
        "        attn_weights = torch.matmul(query, key.transpose(-1, -2))\n",
        "\n",
        "        if self.scale_attn_weights:\n",
        "            attn_weights = attn_weights / torch.tensor(\n",
        "                value.size(-1) ** 0.5, dtype=attn_weights.dtype, device=attn_weights.device\n",
        "            )\n",
        "\n",
        "        # Layer-wise attention scaling\n",
        "        if self.scale_attn_by_inverse_layer_idx:\n",
        "            attn_weights = attn_weights / float(self.layer_idx + 1)\n",
        "\n",
        "        if not self.is_cross_attention:\n",
        "            # if only \"normal\" attention layer implements causal mask\n",
        "            query_length, key_length = query.size(-2), key.size(-2)\n",
        "            causal_mask = self.bias[:, :, key_length - query_length : key_length, :key_length].to(torch.bool)\n",
        "            mask_value = torch.finfo(attn_weights.dtype).min\n",
        "            # Need to be a tensor, otherwise we get error: `RuntimeError: expected scalar type float but found double`.\n",
        "            # Need to be on the same device, otherwise `RuntimeError: ..., x and y to be on the same device`\n",
        "            mask_value = torch.tensor(mask_value, dtype=attn_weights.dtype).to(attn_weights.device)\n",
        "            attn_weights = torch.where(causal_mask, attn_weights, mask_value)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            # Apply the attention mask\n",
        "            attn_weights = attn_weights + attention_mask\n",
        "\n",
        "        attn_weights = nn.functional.softmax(attn_weights, dim=-1)\n",
        "\n",
        "        # Downcast (if necessary) back to V's dtype (if in mixed-precision) -- No-Op otherwise\n",
        "        attn_weights = attn_weights.type(value.dtype)\n",
        "        attn_weights = self.attn_dropout(attn_weights)\n",
        "\n",
        "        # Mask heads if we want to\n",
        "        if head_mask is not None:\n",
        "            attn_weights = attn_weights * head_mask\n",
        "\n",
        "        attn_output = torch.matmul(attn_weights, value)\n",
        "\n",
        "        return attn_output, attn_weights\n",
        "\n",
        "    def _upcast_and_reordered_attn(self, query, key, value, attention_mask=None, head_mask=None):\n",
        "        # Use `torch.baddbmm` (a bit more efficient w/ alpha param for scaling -- from Megatron-LM)\n",
        "        bsz, num_heads, q_seq_len, dk = query.size()\n",
        "        _, _, k_seq_len, _ = key.size()\n",
        "\n",
        "        # Preallocate attn_weights for `baddbmm`\n",
        "        attn_weights = torch.empty(bsz * num_heads, q_seq_len, k_seq_len, dtype=torch.float32, device=query.device)\n",
        "\n",
        "        # Compute Scale Factor\n",
        "        scale_factor = 1.0\n",
        "        if self.scale_attn_weights:\n",
        "            scale_factor /= float(value.size(-1)) ** 0.5\n",
        "\n",
        "        if self.scale_attn_by_inverse_layer_idx:\n",
        "            scale_factor /= float(self.layer_idx + 1)\n",
        "\n",
        "        # Upcast (turn off autocast) and reorder (Scale K by 1 / root(dk))\n",
        "        with autocast(enabled=False):\n",
        "            q, k = query.reshape(-1, q_seq_len, dk), key.transpose(-1, -2).reshape(-1, dk, k_seq_len)\n",
        "            attn_weights = torch.baddbmm(attn_weights, q.float(), k.float(), beta=0, alpha=scale_factor)\n",
        "            attn_weights = attn_weights.reshape(bsz, num_heads, q_seq_len, k_seq_len)\n",
        "\n",
        "        if not self.is_cross_attention:\n",
        "            # if only \"normal\" attention layer implements causal mask\n",
        "            query_length, key_length = query.size(-2), key.size(-2)\n",
        "            causal_mask = self.bias[:, :, key_length - query_length : key_length, :key_length].bool()\n",
        "            mask_value = torch.finfo(attn_weights.dtype).min\n",
        "            # Need to be a tensor, otherwise we get error: `RuntimeError: expected scalar type float but found double`.\n",
        "            # Need to be on the same device, otherwise `RuntimeError: ..., x and y to be on the same device`\n",
        "            mask_value = torch.tensor(mask_value, dtype=attn_weights.dtype).to(attn_weights.device)\n",
        "            attn_weights = torch.where(causal_mask, attn_weights, mask_value)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            # Apply the attention mask\n",
        "            attn_weights = attn_weights + attention_mask\n",
        "\n",
        "        attn_weights = nn.functional.softmax(attn_weights, dim=-1)\n",
        "\n",
        "        # Downcast (if necessary) back to V's dtype (if in mixed-precision) -- No-Op if otherwise\n",
        "        if attn_weights.dtype != torch.float32:\n",
        "            raise RuntimeError(\"Error with upcasting, attn_weights does not have dtype torch.float32\")\n",
        "        attn_weights = attn_weights.type(value.dtype)\n",
        "        attn_weights = self.attn_dropout(attn_weights)\n",
        "\n",
        "        # Mask heads if we want to\n",
        "        if head_mask is not None:\n",
        "            attn_weights = attn_weights * head_mask\n",
        "\n",
        "        attn_output = torch.matmul(attn_weights, value)\n",
        "\n",
        "        return attn_output, attn_weights\n",
        "\n",
        "    def _split_heads(self, tensor, num_heads, attn_head_size):\n",
        "        \"\"\"\n",
        "        Splits hidden_size dim into attn_head_size and num_heads\n",
        "        \"\"\"\n",
        "        new_shape = tensor.size()[:-1] + (num_heads, attn_head_size)\n",
        "        tensor = tensor.view(new_shape) # (batch, seq_len, headnum, head_features)\n",
        "        return tensor.permute(0, 2, 1, 3)  # (batch, head, seq_length, head_features)\n",
        "\n",
        "    def _merge_heads(self, tensor, num_heads, attn_head_size):\n",
        "        \"\"\"\n",
        "        Merges attn_head_size dim and num_attn_heads dim into hidden_size\n",
        "        \"\"\"\n",
        "        tensor = tensor.permute(0, 2, 1, 3).contiguous()\n",
        "        new_shape = tensor.size()[:-2] + (num_heads * attn_head_size,)\n",
        "        return tensor.view(new_shape)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: Optional[Tuple[torch.FloatTensor]],\n",
        "        layer_past: Optional[Tuple[torch.Tensor]] = None,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        use_cache: Optional[bool] = False,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[Union[torch.Tensor, Tuple[torch.Tensor]], ...]:\n",
        "        if encoder_hidden_states is not None:\n",
        "            if not hasattr(self, \"q_attn\"):\n",
        "                raise ValueError(\n",
        "                    \"If class is used as cross attention, the weights `q_attn` have to be defined. \"\n",
        "                    \"Please make sure to instantiate class with `GPT2Attention(..., is_cross_attention=True)`.\"\n",
        "                )\n",
        "\n",
        "            query = self.q_attn(hidden_states)\n",
        "            key, value = self.c_attn(encoder_hidden_states).split(self.split_size, dim=2)\n",
        "            attention_mask = encoder_attention_mask\n",
        "        else:\n",
        "            query, key, value = self.c_attn(hidden_states).split(self.split_size, dim=2)\n",
        "\n",
        "        query = self._split_heads(query, self.num_heads, self.head_dim)\n",
        "        key = self._split_heads(key, self.num_heads, self.head_dim)\n",
        "        value = self._split_heads(value, self.num_heads, self.head_dim)\n",
        "\n",
        "        if layer_past is not None:\n",
        "            past_key, past_value = layer_past\n",
        "            key = torch.cat((past_key, key), dim=-2)\n",
        "            value = torch.cat((past_value, value), dim=-2)\n",
        "\n",
        "        if use_cache is True:\n",
        "            present = (key, value)\n",
        "        else:\n",
        "            present = None\n",
        "\n",
        "        if self.reorder_and_upcast_attn:\n",
        "            attn_output, attn_weights = self._upcast_and_reordered_attn(query, key, value, attention_mask, head_mask)\n",
        "        else:\n",
        "            attn_output, attn_weights = self._attn(query, key, value, attention_mask, head_mask)\n",
        "\n",
        "        attn_output = self._merge_heads(attn_output, self.num_heads, self.head_dim)\n",
        "        attn_output = self.c_proj(attn_output)\n",
        "        attn_output = self.resid_dropout(attn_output)\n",
        "\n",
        "        outputs = (attn_output, present)\n",
        "        if output_attentions:\n",
        "            outputs += (attn_weights,)\n",
        "\n",
        "        return outputs  # a, present, (attentions)\n",
        "```"
      ],
      "metadata": {
        "id": "dlKSe8pzc_GY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP in GPT2.\n",
        "```python\n",
        "class GPT2MLP(nn.Module):\n",
        "    def __init__(self, intermediate_size, config):\n",
        "        super().__init__()\n",
        "        embed_dim = config.hidden_size\n",
        "        self.c_fc = Conv1D(intermediate_size, embed_dim)\n",
        "        self.c_proj = Conv1D(embed_dim, intermediate_size)\n",
        "        self.act = ACT2FN[config.activation_function]\n",
        "        self.dropout = nn.Dropout(config.resid_pdrop)\n",
        "\n",
        "    def forward(self, hidden_states: Optional[Tuple[torch.FloatTensor]]) -> torch.FloatTensor:\n",
        "        hidden_states = self.c_fc(hidden_states)\n",
        "        hidden_states = self.act(hidden_states)\n",
        "        hidden_states = self.c_proj(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        return hidden_states\n",
        "```"
      ],
      "metadata": {
        "id": "0w0ASKLcgCkC"
      }
    }
  ]
}