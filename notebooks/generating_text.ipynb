{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to generate text: using different decoding methods for language generation with Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\src\\transformer-sketchbook\\notebooks\\generating_text.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/generating_text.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model_name_or_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m../models/Wizard-Vicuna-7B-Uncensored-GPTQ\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/generating_text.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m torch_device \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/generating_text.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# To use a different branch, change revision\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/generating_text.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# For example: revision=\"main\"\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/generating_text.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model \u001b[39m=\u001b[39m AutoModelForCausalLM\u001b[39m.\u001b[39mfrom_pretrained(model_name_or_path,\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/generating_text.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                                              device_map\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/generating_text.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                                              trust_remote_code\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/generating_text.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                                              revision\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmain\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mto(torch_device)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_name_or_path = \"../models/Wizard-Vicuna-7B-Uncensored-GPTQ\"\n",
    "\n",
    "torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# To use a different branch, change revision\n",
    "# For example: revision=\"main\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path,\n",
    "                                             device_map=\"auto\",\n",
    "                                             trust_remote_code=True,\n",
    "                                             revision=\"main\").to(torch_device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
    "\n",
    "prompt = \"Tell me about AI\"\n",
    "prompt_template=f'''A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
    "\n",
    "'''\n",
    "model_inputs = tokenizer(prompt_template, return_tensors='pt').to(torch_device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy Search\n",
    "![greedy_search](../images/greedy_search.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "<s> ### instruction : what is the outcome of pitcher 663432 pitching to batter 596115 ### input : Top of the 1 inning with 2 outs ### output : 663432 throws a 87 miles per hour Slider for a strike, 663432 throws a 86 miles per hour Slider for a strike, 663432 throws a 86 miles per hour Slider for a ball, 663432 throws a 86 miles per hour Slider for a strike and 596115 strikeout, event : strikeout, strikeout, event : strikeout, event : strikeout, strikeout, event : strikeout, strikeout, event : strikeout, play, event : strikeout double play, event : strikeout double play, event : strikeout double play, event\n"
     ]
    }
   ],
   "source": [
    "# encode context the generation is conditioned on\n",
    "\n",
    "\n",
    "# generate 40 new tokens\n",
    "greedy_output = model.generate(**model_inputs, max_new_tokens=95)\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(greedy_output[0], skip_special_tokens=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beam search\n",
    "![beam_search](../images/beam_search.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "### instruction : what is the outcome of pitcher 663432 pitching to batter 596115 ### input : Top of the 1 inning with 2 outs ### output : 663432 throws a 88 miles per hour Slider for a strike, 663432 throws a 88 miles per hour Slider for a strike, 663432 throws a 88 miles per hour Slider for a ball, 663432 throws a 88 miles per hour Slider for a strike, 663432 throws a 88 miles per hour Slider for a strike, 663432 throws a 88 miles per hour Slider\n"
     ]
    }
   ],
   "source": [
    "beam_output = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=65,\n",
    "    num_beams=5,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(beam_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "### instruction : what is the outcome of pitcher 663432 pitching to batter 596115 ### input : Top of the 8 inning with 2 outs ### output : 663432 throws a 88 miles per hour Slider for a strike, 663432 throws a 88 miles per hour Slider for for strike, 663432 throws a 88 miles per hour Cutter for a ball, 663432 throws a 88 miles per hour Slider and 596115 hits into a field out, event : field out, event : field out, out, event : field out\n"
     ]
    }
   ],
   "source": [
    "beam_output = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=65,\n",
    "    num_beams=5,\n",
    "    no_repeat_ngram_size=10,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(beam_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: ### instruction : what is the outcome of pitcher 663432 pitching to batter 596115 ### input : Top of the 8 inning with 2 outs ### output : 663432 throws a 88 miles per hour Slider for a strike, 663432 throws a 88 miles per hour Slider for for strike, 663432 throws a 88 miles per hour Cutter for a ball, 663432 throws a 88 miles per hour Slider and 596115 hits into a field out, event : field out, event : field out, out, event : field out\n",
      "1: ### instruction : what is the outcome of pitcher 663432 pitching to batter 596115 ### input : Top of the 8 inning with 2 outs ### output : 663432 throws a 88 miles per hour Slider for a strike, 663432 throws a 88 miles per hour Slider for for strike, 663432 throws a 88 miles per hour Changeup for a ball, 663432 throws a 88 miles per hour Slider and 596115 hits into a field out, event : field out, event : field out, out, event : field out\n",
      "2: ### instruction : what is the outcome of pitcher 663432 pitching to batter 596115 ### input : Top of the 8 inning with 2 outs ### output : 663432 throws a 88 miles per hour Slider for a strike, 663432 throws a 88 miles per hour Slider for stealing strike, 663432 throws a 88 miles per hour Cutter for a ball, 663432 throws a 88 miles per hour Slider and 596115 hits into a field out, event : field out, event : field out, out, event : field out\n",
      "3: ### instruction : what is the outcome of pitcher 663432 pitching to batter 596115 ### input : Top of the 8 inning with 2 outs ### output : 663432 throws a 88 miles per hour Slider for a strike, 663432 throws a 88 miles per hour Slider for for strike, 663432 throws a 88 miles per hour Cutter for a ball, 663432 throws a 88 miles per hour Slider and 596115 hits into a field out, event : field out, event : field out, out, field out, event\n",
      "4: ### instruction : what is the outcome of pitcher 663432 pitching to batter 596115 ### input : Top of the 8 inning with 2 outs ### output : 663432 throws a 88 miles per hour Slider for a strike, 663432 throws a 88 miles per hour Slider for for strike, 663432 throws a 88 miles per hour Cutter for a ball, 663432 throws a 88 miles per hour Slider and 596115 hits into a field out, event : field out, event : field out, out, hits : field out\n"
     ]
    }
   ],
   "source": [
    "# set return_num_sequences > 1\n",
    "beam_outputs = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=65,\n",
    "    num_beams=5,\n",
    "    no_repeat_ngram_size=10,\n",
    "    num_return_sequences=5,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "# now we have 3 output sequences\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "for i, beam_output in enumerate(beam_outputs):\n",
    "  print(\"{}: {}\".format(i, tokenizer.decode(beam_output, skip_special_tokens=True)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling\n",
    "![Sampling](../images/sampling_search.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import set_seed\n",
    "set_seed(42)\n",
    "\n",
    "# activate sampling and deactivate top_k by setting top_k sampling to 0\n",
    "sample_output = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=40,\n",
    "    do_sample=True,\n",
    "    top_k=0\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling w/Temperature\n",
    "![Sampling](../images/sampling_search_with_temp.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed to reproduce results. Feel free to change the seed though to get different results\n",
    "set_seed(42)\n",
    "\n",
    "# use temperature to decrease the sensitivity to low probability candidates\n",
    "sample_output = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=40,\n",
    "    do_sample=True,\n",
    "    top_k=0,\n",
    "    temperature=0.6,\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top-K Sampling\n",
    "![Top-K](../images/top_k_sampling.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed to reproduce results. Feel free to change the seed though to get different results\n",
    "set_seed(42)\n",
    "\n",
    "# set top_k to 50\n",
    "sample_output = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=40,\n",
    "    do_sample=True,\n",
    "    top_k=50\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top-p (nucleus) sampling\n",
    "![Top-K](../images/top_p_sampling.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed to reproduce results. Feel free to change the seed though to get different results\n",
    "set_seed(42)\n",
    "\n",
    "# set top_k to 50\n",
    "sample_output = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=40,\n",
    "    do_sample=True,\n",
    "    top_p=0.92,\n",
    "    top_k=0\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed to reproduce results. Feel free to change the seed though to get different results\n",
    "set_seed(42)\n",
    "\n",
    "# set top_k = 50 and set top_p = 0.95 and num_return_sequences = 3\n",
    "sample_outputs = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=40,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    num_return_sequences=3,\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "for i, sample_output in enumerate(sample_outputs):\n",
    "  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save a custom decoding strategy with your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, GenerationConfig\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"my_account/my_model\")\n",
    "generation_config = GenerationConfig(\n",
    "    max_new_tokens=50, do_sample=True, top_k=50, eos_token_id=model.config.eos_token_id\n",
    ")\n",
    "generation_config.save_pretrained(\"my_account/my_model\", push_to_hub=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
