{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to generate text: using different decoding methods for language generation with Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danm\\Downloads\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\transformers\\modeling_utils.py:429: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  with safe_open(checkpoint_file, framework=\"pt\") as f:\n",
      "c:\\Users\\danm\\Downloads\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "c:\\Users\\danm\\Downloads\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\torch\\storage.py:899: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = cls(wrap_storage=untyped_storage)\n",
      "c:\\Users\\danm\\Downloads\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\safetensors\\torch.py:99: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  with safe_open(filename, framework=\"pt\", device=device) as f:\n",
      "Some weights of the model checkpoint at ../models/Wizard-Vicuna-7B-Uncensored-GPTQ were not used when initializing LlamaForCausalLM: ['model.layers.30.self_attn.o_proj.qzeros', 'model.layers.24.mlp.up_proj.qweight', 'model.layers.15.self_attn.o_proj.scales', 'model.layers.16.self_attn.o_proj.qweight', 'model.layers.13.self_attn.o_proj.qweight', 'model.layers.27.mlp.up_proj.scales', 'model.layers.29.mlp.down_proj.scales', 'model.layers.4.self_attn.k_proj.qzeros', 'model.layers.11.mlp.up_proj.scales', 'model.layers.8.mlp.up_proj.scales', 'model.layers.10.mlp.gate_proj.bias', 'model.layers.11.mlp.down_proj.scales', 'model.layers.14.mlp.gate_proj.qweight', 'model.layers.16.mlp.up_proj.scales', 'model.layers.21.mlp.up_proj.bias', 'model.layers.14.self_attn.q_proj.qzeros', 'model.layers.29.self_attn.k_proj.scales', 'model.layers.4.mlp.up_proj.qzeros', 'model.layers.5.mlp.gate_proj.bias', 'model.layers.2.mlp.up_proj.scales', 'model.layers.31.mlp.down_proj.scales', 'model.layers.8.self_attn.o_proj.qzeros', 'model.layers.7.mlp.down_proj.bias', 'model.layers.25.mlp.down_proj.bias', 'model.layers.3.mlp.gate_proj.qzeros', 'model.layers.24.mlp.gate_proj.bias', 'model.layers.4.mlp.gate_proj.bias', 'model.layers.31.self_attn.v_proj.qweight', 'model.layers.11.self_attn.v_proj.scales', 'model.layers.20.self_attn.k_proj.qzeros', 'model.layers.7.mlp.down_proj.qweight', 'model.layers.31.mlp.gate_proj.bias', 'model.layers.24.mlp.up_proj.scales', 'model.layers.18.mlp.down_proj.scales', 'model.layers.28.self_attn.q_proj.bias', 'model.layers.13.mlp.gate_proj.bias', 'model.layers.31.mlp.down_proj.bias', 'model.layers.5.self_attn.o_proj.scales', 'model.layers.29.self_attn.o_proj.scales', 'model.layers.23.mlp.gate_proj.qweight', 'model.layers.14.self_attn.k_proj.qweight', 'model.layers.31.mlp.up_proj.qweight', 'model.layers.11.self_attn.v_proj.qweight', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.22.self_attn.q_proj.qweight', 'model.layers.0.mlp.up_proj.scales', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.24.mlp.down_proj.scales', 'model.layers.3.mlp.down_proj.qweight', 'model.layers.23.mlp.down_proj.qweight', 'model.layers.25.mlp.up_proj.scales', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.30.self_attn.v_proj.qzeros', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.5.mlp.down_proj.qzeros', 'model.layers.13.self_attn.o_proj.scales', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.19.self_attn.k_proj.qzeros', 'model.layers.31.mlp.gate_proj.scales', 'model.layers.19.self_attn.v_proj.qweight', 'model.layers.17.self_attn.q_proj.qzeros', 'model.layers.14.mlp.up_proj.qzeros', 'model.layers.7.self_attn.q_proj.qzeros', 'model.layers.12.mlp.up_proj.qzeros', 'model.layers.29.mlp.gate_proj.qweight', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.6.mlp.up_proj.scales', 'model.layers.4.self_attn.q_proj.qzeros', 'model.layers.2.mlp.gate_proj.scales', 'model.layers.22.self_attn.q_proj.qzeros', 'model.layers.29.self_attn.v_proj.qzeros', 'model.layers.16.mlp.gate_proj.scales', 'model.layers.27.mlp.gate_proj.qzeros', 'model.layers.27.self_attn.q_proj.qweight', 'model.layers.16.mlp.down_proj.qweight', 'model.layers.23.mlp.up_proj.scales', 'model.layers.15.mlp.up_proj.qzeros', 'model.layers.21.mlp.up_proj.qweight', 'model.layers.12.mlp.gate_proj.scales', 'model.layers.3.self_attn.o_proj.qweight', 'model.layers.24.self_attn.k_proj.bias', 'model.layers.13.self_attn.q_proj.qzeros', 'model.layers.3.self_attn.k_proj.qzeros', 'model.layers.16.self_attn.o_proj.scales', 'model.layers.20.mlp.gate_proj.qweight', 'model.layers.18.mlp.down_proj.qweight', 'model.layers.1.self_attn.o_proj.scales', 'model.layers.22.mlp.down_proj.scales', 'model.layers.23.mlp.gate_proj.bias', 'model.layers.7.self_attn.o_proj.bias', 'model.layers.30.self_attn.q_proj.bias', 'model.layers.7.self_attn.k_proj.scales', 'model.layers.29.mlp.gate_proj.scales', 'model.layers.8.self_attn.v_proj.qweight', 'model.layers.14.mlp.gate_proj.scales', 'model.layers.3.self_attn.v_proj.scales', 'model.layers.19.self_attn.k_proj.scales', 'model.layers.20.self_attn.v_proj.qzeros', 'model.layers.28.self_attn.k_proj.scales', 'model.layers.28.mlp.up_proj.scales', 'model.layers.4.self_attn.q_proj.qweight', 'model.layers.4.mlp.gate_proj.qzeros', 'model.layers.0.self_attn.v_proj.scales', 'model.layers.16.self_attn.o_proj.bias', 'model.layers.2.self_attn.k_proj.qweight', 'model.layers.9.mlp.up_proj.qzeros', 'model.layers.23.mlp.down_proj.scales', 'model.layers.18.mlp.down_proj.bias', 'model.layers.22.mlp.gate_proj.bias', 'model.layers.25.self_attn.k_proj.qzeros', 'model.layers.20.mlp.up_proj.scales', 'model.layers.23.self_attn.q_proj.bias', 'model.layers.26.self_attn.o_proj.qweight', 'model.layers.2.mlp.down_proj.scales', 'model.layers.29.mlp.gate_proj.bias', 'model.layers.11.mlp.gate_proj.scales', 'model.layers.28.self_attn.v_proj.bias', 'model.layers.8.self_attn.o_proj.bias', 'model.layers.1.self_attn.o_proj.qzeros', 'model.layers.21.self_attn.o_proj.bias', 'model.layers.27.self_attn.o_proj.scales', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.0.mlp.down_proj.bias', 'model.layers.21.mlp.down_proj.qweight', 'model.layers.2.mlp.gate_proj.qzeros', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.11.mlp.down_proj.bias', 'model.layers.16.self_attn.q_proj.qzeros', 'model.layers.21.self_attn.k_proj.qweight', 'model.layers.22.mlp.up_proj.scales', 'model.layers.5.self_attn.k_proj.qweight', 'model.layers.28.mlp.up_proj.qweight', 'model.layers.8.mlp.gate_proj.bias', 'model.layers.11.self_attn.q_proj.scales', 'model.layers.28.self_attn.o_proj.qweight', 'model.layers.26.mlp.down_proj.scales', 'model.layers.4.mlp.gate_proj.qweight', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.1.self_attn.k_proj.qweight', 'model.layers.13.mlp.gate_proj.qweight', 'model.layers.24.self_attn.v_proj.qzeros', 'model.layers.8.mlp.up_proj.qweight', 'model.layers.26.mlp.down_proj.qzeros', 'model.layers.31.self_attn.q_proj.qzeros', 'model.layers.8.self_attn.k_proj.scales', 'model.layers.26.self_attn.o_proj.scales', 'model.layers.30.self_attn.o_proj.bias', 'model.layers.4.mlp.up_proj.qweight', 'model.layers.27.self_attn.q_proj.scales', 'model.layers.9.self_attn.o_proj.qweight', 'model.layers.17.mlp.gate_proj.scales', 'model.layers.7.mlp.down_proj.qzeros', 'model.layers.15.self_attn.v_proj.qweight', 'model.layers.25.mlp.up_proj.qzeros', 'model.layers.1.mlp.up_proj.qzeros', 'model.layers.14.self_attn.v_proj.scales', 'model.layers.8.self_attn.q_proj.qzeros', 'model.layers.27.self_attn.q_proj.qzeros', 'model.layers.10.mlp.down_proj.qweight', 'model.layers.29.self_attn.q_proj.bias', 'model.layers.6.self_attn.o_proj.qzeros', 'model.layers.28.self_attn.o_proj.scales', 'model.layers.23.self_attn.k_proj.bias', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.16.self_attn.q_proj.scales', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.18.self_attn.v_proj.scales', 'model.layers.4.self_attn.o_proj.scales', 'model.layers.17.self_attn.k_proj.qweight', 'model.layers.30.mlp.down_proj.qzeros', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.31.mlp.gate_proj.qzeros', 'model.layers.9.mlp.gate_proj.qweight', 'model.layers.29.self_attn.o_proj.bias', 'model.layers.2.self_attn.v_proj.qzeros', 'model.layers.24.self_attn.o_proj.qweight', 'model.layers.31.mlp.up_proj.bias', 'model.layers.21.self_attn.q_proj.qzeros', 'model.layers.4.self_attn.v_proj.qzeros', 'model.layers.17.mlp.up_proj.qweight', 'model.layers.18.self_attn.o_proj.scales', 'model.layers.12.self_attn.k_proj.qweight', 'model.layers.4.mlp.down_proj.scales', 'model.layers.31.self_attn.q_proj.scales', 'model.layers.13.mlp.up_proj.qweight', 'model.layers.2.self_attn.k_proj.qzeros', 'model.layers.7.mlp.up_proj.qzeros', 'model.layers.20.mlp.down_proj.scales', 'model.layers.8.mlp.up_proj.qzeros', 'model.layers.2.self_attn.q_proj.scales', 'model.layers.26.self_attn.q_proj.scales', 'model.layers.5.self_attn.q_proj.scales', 'model.layers.12.self_attn.q_proj.qweight', 'model.layers.18.mlp.gate_proj.qzeros', 'model.layers.2.self_attn.o_proj.bias', 'model.layers.6.mlp.gate_proj.qzeros', 'model.layers.19.self_attn.k_proj.qweight', 'model.layers.0.mlp.gate_proj.qzeros', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.22.mlp.up_proj.qzeros', 'model.layers.11.self_attn.q_proj.qzeros', 'model.layers.8.mlp.down_proj.qweight', 'model.layers.16.mlp.down_proj.bias', 'model.layers.11.mlp.gate_proj.qzeros', 'model.layers.27.mlp.up_proj.bias', 'model.layers.2.mlp.gate_proj.bias', 'model.layers.20.self_attn.v_proj.bias', 'model.layers.2.mlp.up_proj.qzeros', 'model.layers.30.self_attn.k_proj.qzeros', 'model.layers.20.self_attn.k_proj.scales', 'model.layers.12.self_attn.o_proj.qweight', 'model.layers.18.self_attn.k_proj.qweight', 'model.layers.18.self_attn.o_proj.qweight', 'model.layers.27.self_attn.o_proj.qweight', 'model.layers.15.self_attn.k_proj.scales', 'model.layers.30.mlp.up_proj.qweight', 'model.layers.7.mlp.gate_proj.qweight', 'model.layers.25.mlp.down_proj.scales', 'model.layers.24.self_attn.v_proj.bias', 'model.layers.7.self_attn.k_proj.qweight', 'model.layers.8.mlp.down_proj.bias', 'model.layers.28.mlp.up_proj.bias', 'model.layers.4.mlp.down_proj.qzeros', 'model.layers.9.self_attn.o_proj.qzeros', 'model.layers.12.mlp.up_proj.qweight', 'model.layers.24.mlp.down_proj.bias', 'model.layers.24.mlp.down_proj.qzeros', 'model.layers.5.mlp.up_proj.qzeros', 'model.layers.9.self_attn.q_proj.qzeros', 'model.layers.19.mlp.up_proj.bias', 'model.layers.19.self_attn.o_proj.qweight', 'model.layers.27.self_attn.o_proj.qzeros', 'model.layers.21.self_attn.o_proj.scales', 'model.layers.24.mlp.up_proj.qzeros', 'model.layers.12.self_attn.v_proj.scales', 'model.layers.11.mlp.down_proj.qzeros', 'model.layers.6.self_attn.q_proj.qweight', 'model.layers.18.self_attn.k_proj.bias', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.22.mlp.up_proj.bias', 'model.layers.21.mlp.up_proj.scales', 'model.layers.24.mlp.gate_proj.qweight', 'model.layers.16.self_attn.v_proj.bias', 'model.layers.21.self_attn.v_proj.bias', 'model.layers.9.self_attn.k_proj.scales', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.17.self_attn.o_proj.bias', 'model.layers.18.mlp.gate_proj.scales', 'model.layers.21.self_attn.v_proj.scales', 'model.layers.0.self_attn.k_proj.scales', 'model.layers.18.self_attn.o_proj.qzeros', 'model.layers.26.self_attn.o_proj.qzeros', 'model.layers.30.self_attn.k_proj.qweight', 'model.layers.30.self_attn.k_proj.scales', 'model.layers.19.mlp.down_proj.qzeros', 'model.layers.20.self_attn.o_proj.scales', 'model.layers.0.self_attn.o_proj.bias', 'model.layers.22.self_attn.q_proj.bias', 'model.layers.17.mlp.down_proj.qzeros', 'model.layers.1.self_attn.q_proj.qweight', 'model.layers.22.mlp.gate_proj.scales', 'model.layers.22.self_attn.k_proj.qweight', 'model.layers.17.mlp.gate_proj.qweight', 'model.layers.12.mlp.down_proj.qweight', 'model.layers.31.self_attn.o_proj.bias', 'model.layers.2.self_attn.q_proj.qweight', 'model.layers.17.mlp.down_proj.scales', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.26.mlp.gate_proj.qweight', 'model.layers.24.self_attn.q_proj.qweight', 'model.layers.28.self_attn.v_proj.qweight', 'model.layers.23.self_attn.k_proj.scales', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.7.mlp.up_proj.bias', 'model.layers.18.mlp.up_proj.bias', 'model.layers.9.mlp.down_proj.bias', 'model.layers.3.self_attn.o_proj.qzeros', 'model.layers.13.mlp.down_proj.bias', 'model.layers.24.self_attn.q_proj.scales', 'model.layers.0.mlp.gate_proj.bias', 'model.layers.18.self_attn.k_proj.qzeros', 'model.layers.18.self_attn.q_proj.scales', 'model.layers.20.mlp.gate_proj.bias', 'model.layers.30.mlp.up_proj.qzeros', 'model.layers.9.self_attn.q_proj.qweight', 'model.layers.26.self_attn.o_proj.bias', 'model.layers.28.mlp.down_proj.qzeros', 'model.layers.14.mlp.down_proj.bias', 'model.layers.4.self_attn.o_proj.qweight', 'model.layers.31.self_attn.v_proj.scales', 'model.layers.19.self_attn.v_proj.bias', 'model.layers.26.self_attn.v_proj.qweight', 'model.layers.19.self_attn.v_proj.scales', 'model.layers.2.mlp.gate_proj.qweight', 'model.layers.25.self_attn.q_proj.qweight', 'model.layers.9.self_attn.k_proj.qzeros', 'model.layers.20.self_attn.q_proj.scales', 'model.layers.22.self_attn.k_proj.bias', 'model.layers.6.mlp.gate_proj.bias', 'model.layers.0.mlp.up_proj.bias', 'model.layers.0.mlp.down_proj.qzeros', 'model.layers.11.self_attn.v_proj.qzeros', 'model.layers.12.mlp.up_proj.bias', 'model.layers.22.mlp.up_proj.qweight', 'model.layers.29.mlp.up_proj.scales', 'model.layers.26.self_attn.q_proj.bias', 'model.layers.23.mlp.gate_proj.scales', 'model.layers.3.self_attn.q_proj.qweight', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.19.self_attn.o_proj.qzeros', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.30.self_attn.k_proj.bias', 'model.layers.17.self_attn.q_proj.qweight', 'model.layers.27.self_attn.k_proj.qweight', 'model.layers.25.self_attn.q_proj.scales', 'model.layers.1.mlp.down_proj.qzeros', 'model.layers.16.self_attn.o_proj.qzeros', 'model.layers.17.self_attn.v_proj.qweight', 'model.layers.12.mlp.gate_proj.qweight', 'model.layers.31.self_attn.k_proj.scales', 'model.layers.14.self_attn.o_proj.bias', 'model.layers.15.self_attn.o_proj.qzeros', 'model.layers.18.self_attn.k_proj.scales', 'model.layers.28.mlp.gate_proj.qzeros', 'model.layers.24.self_attn.o_proj.bias', 'model.layers.6.self_attn.k_proj.qzeros', 'model.layers.22.self_attn.v_proj.qzeros', 'model.layers.25.mlp.gate_proj.bias', 'model.layers.20.self_attn.o_proj.qzeros', 'model.layers.7.self_attn.o_proj.scales', 'model.layers.1.mlp.gate_proj.qzeros', 'model.layers.9.self_attn.q_proj.scales', 'model.layers.1.self_attn.k_proj.qzeros', 'model.layers.9.mlp.gate_proj.bias', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.0.mlp.gate_proj.qweight', 'model.layers.15.self_attn.q_proj.qzeros', 'model.layers.21.mlp.gate_proj.bias', 'model.layers.14.self_attn.o_proj.scales', 'model.layers.23.mlp.gate_proj.qzeros', 'model.layers.25.self_attn.v_proj.bias', 'model.layers.16.self_attn.v_proj.scales', 'model.layers.13.mlp.down_proj.scales', 'model.layers.2.self_attn.o_proj.scales', 'model.layers.23.self_attn.o_proj.qweight', 'model.layers.1.mlp.gate_proj.bias', 'model.layers.30.self_attn.q_proj.scales', 'model.layers.8.mlp.down_proj.qzeros', 'model.layers.2.mlp.down_proj.bias', 'model.layers.25.self_attn.v_proj.qzeros', 'model.layers.26.self_attn.k_proj.qzeros', 'model.layers.0.mlp.down_proj.scales', 'model.layers.29.self_attn.k_proj.qweight', 'model.layers.1.self_attn.q_proj.scales', 'model.layers.30.self_attn.o_proj.scales', 'model.layers.0.mlp.up_proj.qzeros', 'model.layers.8.mlp.gate_proj.qzeros', 'model.layers.31.self_attn.o_proj.scales', 'model.layers.4.mlp.down_proj.qweight', 'model.layers.14.mlp.gate_proj.bias', 'model.layers.11.self_attn.o_proj.qzeros', 'model.layers.14.self_attn.q_proj.scales', 'model.layers.10.mlp.up_proj.scales', 'model.layers.27.self_attn.v_proj.qzeros', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.9.self_attn.v_proj.qzeros', 'model.layers.15.mlp.down_proj.qzeros', 'model.layers.17.mlp.down_proj.bias', 'model.layers.26.mlp.down_proj.bias', 'model.layers.30.self_attn.v_proj.bias', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.17.self_attn.v_proj.bias', 'model.layers.20.mlp.gate_proj.qzeros', 'model.layers.31.mlp.up_proj.qzeros', 'model.layers.31.self_attn.o_proj.qzeros', 'model.layers.9.self_attn.v_proj.qweight', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.28.self_attn.k_proj.qzeros', 'model.layers.28.self_attn.q_proj.scales', 'model.layers.29.self_attn.o_proj.qweight', 'model.layers.26.mlp.up_proj.scales', 'model.layers.28.mlp.gate_proj.bias', 'model.layers.4.self_attn.v_proj.scales', 'model.layers.4.mlp.down_proj.bias', 'model.layers.0.self_attn.o_proj.qzeros', 'model.layers.19.mlp.down_proj.qweight', 'model.layers.5.self_attn.o_proj.bias', 'model.layers.4.self_attn.o_proj.qzeros', 'model.layers.24.self_attn.k_proj.qweight', 'model.layers.27.mlp.down_proj.bias', 'model.layers.14.self_attn.v_proj.qzeros', 'model.layers.15.self_attn.k_proj.qweight', 'model.layers.20.mlp.up_proj.bias', 'model.layers.29.self_attn.k_proj.qzeros', 'model.layers.10.self_attn.o_proj.bias', 'model.layers.15.mlp.down_proj.scales', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.0.self_attn.o_proj.qweight', 'model.layers.1.self_attn.v_proj.scales', 'model.layers.21.self_attn.q_proj.qweight', 'model.layers.3.mlp.gate_proj.bias', 'model.layers.16.self_attn.k_proj.qzeros', 'model.layers.21.self_attn.o_proj.qweight', 'model.layers.6.self_attn.v_proj.qweight', 'model.layers.25.self_attn.o_proj.bias', 'model.layers.23.self_attn.q_proj.qzeros', 'model.layers.15.mlp.down_proj.bias', 'model.layers.31.self_attn.q_proj.bias', 'model.layers.8.self_attn.q_proj.scales', 'model.layers.25.self_attn.k_proj.bias', 'model.layers.9.mlp.up_proj.qweight', 'model.layers.15.self_attn.k_proj.qzeros', 'model.layers.27.self_attn.v_proj.qweight', 'model.layers.16.self_attn.k_proj.scales', 'model.layers.27.self_attn.v_proj.bias', 'model.layers.26.self_attn.q_proj.qzeros', 'model.layers.26.self_attn.k_proj.bias', 'model.layers.18.self_attn.q_proj.bias', 'model.layers.14.self_attn.o_proj.qweight', 'model.layers.21.self_attn.v_proj.qzeros', 'model.layers.30.self_attn.q_proj.qzeros', 'model.layers.12.mlp.up_proj.scales', 'model.layers.7.self_attn.o_proj.qweight', 'model.layers.18.mlp.up_proj.qweight', 'model.layers.31.mlp.up_proj.scales', 'model.layers.16.self_attn.v_proj.qzeros', 'model.layers.19.self_attn.o_proj.scales', 'model.layers.17.self_attn.k_proj.scales', 'model.layers.19.self_attn.q_proj.scales', 'model.layers.23.mlp.down_proj.bias', 'model.layers.5.self_attn.v_proj.scales', 'model.layers.7.mlp.gate_proj.qzeros', 'model.layers.9.self_attn.v_proj.bias', 'model.layers.29.mlp.up_proj.qzeros', 'model.layers.22.mlp.gate_proj.qweight', 'model.layers.23.self_attn.k_proj.qzeros', 'model.layers.28.self_attn.k_proj.qweight', 'model.layers.16.self_attn.q_proj.bias', 'model.layers.5.self_attn.v_proj.qzeros', 'model.layers.27.self_attn.o_proj.bias', 'model.layers.23.mlp.down_proj.qzeros', 'model.layers.25.self_attn.q_proj.qzeros', 'model.layers.6.self_attn.o_proj.bias', 'model.layers.27.mlp.up_proj.qzeros', 'model.layers.8.mlp.up_proj.bias', 'model.layers.12.mlp.down_proj.bias', 'model.layers.10.self_attn.k_proj.scales', 'model.layers.27.self_attn.k_proj.bias', 'model.layers.29.mlp.up_proj.qweight', 'model.layers.12.self_attn.k_proj.scales', 'model.layers.11.mlp.gate_proj.qweight', 'model.layers.15.self_attn.v_proj.scales', 'model.layers.24.mlp.gate_proj.qzeros', 'model.layers.24.self_attn.q_proj.qzeros', 'model.layers.19.self_attn.q_proj.bias', 'model.layers.22.self_attn.v_proj.scales', 'model.layers.26.mlp.gate_proj.bias', 'model.layers.24.self_attn.k_proj.scales', 'model.layers.23.mlp.up_proj.bias', 'model.layers.19.self_attn.o_proj.bias', 'model.layers.18.self_attn.v_proj.qweight', 'model.layers.25.self_attn.v_proj.scales', 'model.layers.13.mlp.up_proj.bias', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.26.self_attn.v_proj.bias', 'model.layers.7.self_attn.v_proj.qweight', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.0.self_attn.k_proj.qweight', 'model.layers.15.self_attn.o_proj.bias', 'model.layers.28.mlp.down_proj.bias', 'model.layers.24.mlp.gate_proj.scales', 'model.layers.29.mlp.down_proj.qweight', 'model.layers.26.self_attn.k_proj.scales', 'model.layers.26.self_attn.v_proj.qzeros', 'model.layers.31.self_attn.v_proj.bias', 'model.layers.13.self_attn.k_proj.scales', 'model.layers.17.self_attn.v_proj.qzeros', 'model.layers.17.self_attn.k_proj.bias', 'model.layers.19.mlp.up_proj.qweight', 'model.layers.1.self_attn.o_proj.qweight', 'model.layers.10.mlp.up_proj.qzeros', 'model.layers.22.mlp.gate_proj.qzeros', 'model.layers.10.self_attn.v_proj.scales', 'model.layers.29.mlp.down_proj.bias', 'model.layers.19.self_attn.q_proj.qzeros', 'model.layers.10.mlp.gate_proj.qzeros', 'model.layers.29.self_attn.k_proj.bias', 'model.layers.14.mlp.gate_proj.qzeros', 'model.layers.9.self_attn.o_proj.scales', 'model.layers.0.self_attn.o_proj.scales', 'model.layers.13.mlp.down_proj.qzeros', 'model.layers.14.self_attn.o_proj.qzeros', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.30.self_attn.o_proj.qweight', 'model.layers.7.mlp.gate_proj.scales', 'model.layers.7.mlp.up_proj.qweight', 'model.layers.24.mlp.down_proj.qweight', 'model.layers.3.mlp.gate_proj.scales', 'model.layers.13.mlp.gate_proj.qzeros', 'model.layers.9.mlp.gate_proj.qzeros', 'model.layers.8.mlp.down_proj.scales', 'model.layers.1.self_attn.v_proj.qzeros', 'model.layers.8.self_attn.o_proj.scales', 'model.layers.23.self_attn.v_proj.qzeros', 'model.layers.11.mlp.up_proj.bias', 'model.layers.23.self_attn.k_proj.qweight', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.10.self_attn.k_proj.qweight', 'model.layers.21.mlp.gate_proj.qzeros', 'model.layers.25.mlp.down_proj.qzeros', 'model.layers.27.mlp.gate_proj.bias', 'model.layers.6.mlp.down_proj.qzeros', 'model.layers.0.self_attn.q_proj.qweight', 'model.layers.14.self_attn.q_proj.bias', 'model.layers.3.mlp.up_proj.bias', 'model.layers.1.self_attn.v_proj.qweight', 'model.layers.3.self_attn.q_proj.qzeros', 'model.layers.7.self_attn.q_proj.qweight', 'model.layers.7.self_attn.o_proj.qzeros', 'model.layers.30.mlp.down_proj.scales', 'model.layers.12.self_attn.o_proj.scales', 'model.layers.26.mlp.up_proj.qzeros', 'model.layers.15.mlp.gate_proj.qweight', 'model.layers.22.self_attn.k_proj.qzeros', 'model.layers.18.mlp.gate_proj.bias', 'model.layers.3.self_attn.k_proj.qweight', 'model.layers.13.self_attn.o_proj.qzeros', 'model.layers.30.mlp.up_proj.scales', 'model.layers.25.mlp.gate_proj.scales', 'model.layers.17.self_attn.q_proj.bias', 'model.layers.17.mlp.down_proj.qweight', 'model.layers.25.self_attn.k_proj.qweight', 'model.layers.7.mlp.gate_proj.bias', 'model.layers.14.mlp.up_proj.bias', 'model.layers.17.self_attn.o_proj.scales', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.22.self_attn.o_proj.qweight', 'model.layers.23.mlp.up_proj.qweight', 'model.layers.28.self_attn.v_proj.qzeros', 'model.layers.0.self_attn.v_proj.qzeros', 'model.layers.15.mlp.up_proj.qweight', 'model.layers.14.self_attn.q_proj.qweight', 'model.layers.28.self_attn.o_proj.bias', 'model.layers.25.mlp.gate_proj.qweight', 'model.layers.14.self_attn.k_proj.scales', 'model.layers.21.self_attn.v_proj.qweight', 'model.layers.11.self_attn.k_proj.qweight', 'model.layers.29.self_attn.q_proj.qweight', 'model.layers.16.mlp.up_proj.qzeros', 'model.layers.27.self_attn.v_proj.scales', 'model.layers.31.self_attn.k_proj.qzeros', 'model.layers.29.self_attn.o_proj.qzeros', 'model.layers.21.self_attn.q_proj.bias', 'model.layers.29.self_attn.q_proj.scales', 'model.layers.23.self_attn.o_proj.bias', 'model.layers.1.mlp.up_proj.qweight', 'model.layers.11.self_attn.k_proj.qzeros', 'model.layers.29.mlp.gate_proj.qzeros', 'model.layers.3.self_attn.q_proj.scales', 'model.layers.14.self_attn.v_proj.qweight', 'model.layers.16.mlp.up_proj.bias', 'model.layers.21.self_attn.k_proj.scales', 'model.layers.29.mlp.down_proj.qzeros', 'model.layers.18.self_attn.v_proj.qzeros', 'model.layers.0.self_attn.q_proj.qzeros', 'model.layers.7.self_attn.v_proj.qzeros', 'model.layers.14.mlp.down_proj.scales', 'model.layers.8.self_attn.k_proj.qzeros', 'model.layers.30.self_attn.q_proj.qweight', 'model.layers.0.self_attn.v_proj.qweight', 'model.layers.23.self_attn.q_proj.scales', 'model.layers.31.mlp.down_proj.qweight', 'model.layers.31.mlp.gate_proj.qweight', 'model.layers.4.self_attn.v_proj.qweight', 'model.layers.12.self_attn.o_proj.bias', 'model.layers.16.self_attn.k_proj.qweight', 'model.layers.18.self_attn.q_proj.qweight', 'model.layers.21.self_attn.o_proj.qzeros', 'model.layers.3.mlp.up_proj.qzeros', 'model.layers.6.self_attn.v_proj.qzeros', 'model.layers.2.self_attn.k_proj.scales', 'model.layers.27.mlp.down_proj.qweight', 'model.layers.2.self_attn.v_proj.scales', 'model.layers.22.self_attn.v_proj.qweight', 'model.layers.26.self_attn.v_proj.scales', 'model.layers.8.self_attn.k_proj.qweight', 'model.layers.18.mlp.gate_proj.qweight', 'model.layers.2.mlp.down_proj.qzeros', 'model.layers.2.mlp.up_proj.qweight', 'model.layers.26.mlp.up_proj.bias', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.6.self_attn.o_proj.qweight', 'model.layers.24.self_attn.o_proj.qzeros', 'model.layers.0.self_attn.q_proj.scales', 'model.layers.20.mlp.down_proj.bias', 'model.layers.24.self_attn.o_proj.scales', 'model.layers.0.mlp.up_proj.qweight', 'model.layers.16.mlp.down_proj.scales', 'model.layers.20.self_attn.o_proj.qweight', 'model.layers.17.mlp.up_proj.qzeros', 'model.layers.13.self_attn.v_proj.qzeros', 'model.layers.28.self_attn.o_proj.qzeros', 'model.layers.26.mlp.gate_proj.scales', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.27.mlp.down_proj.scales', 'model.layers.11.self_attn.o_proj.qweight', 'model.layers.24.mlp.up_proj.bias', 'model.layers.26.mlp.up_proj.qweight', 'model.layers.19.mlp.up_proj.scales', 'model.layers.15.self_attn.q_proj.qweight', 'model.layers.3.mlp.gate_proj.qweight', 'model.layers.19.self_attn.v_proj.qzeros', 'model.layers.2.self_attn.o_proj.qzeros', 'model.layers.8.self_attn.q_proj.qweight', 'model.layers.26.mlp.gate_proj.qzeros', 'model.layers.25.self_attn.o_proj.qweight', 'model.layers.15.mlp.up_proj.bias', 'model.layers.5.mlp.gate_proj.qzeros', 'model.layers.10.self_attn.v_proj.qweight', 'model.layers.1.self_attn.o_proj.bias', 'model.layers.13.self_attn.k_proj.qzeros', 'model.layers.20.self_attn.q_proj.qzeros', 'model.layers.12.self_attn.q_proj.qzeros', 'model.layers.3.self_attn.v_proj.qweight', 'model.layers.30.mlp.gate_proj.scales', 'model.layers.5.mlp.down_proj.bias', 'model.layers.5.self_attn.v_proj.qweight', 'model.layers.1.mlp.down_proj.qweight', 'model.layers.12.mlp.gate_proj.qzeros', 'model.layers.7.self_attn.v_proj.scales', 'model.layers.25.mlp.up_proj.qweight', 'model.layers.3.mlp.down_proj.qzeros', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.2.self_attn.o_proj.qweight', 'model.layers.11.mlp.down_proj.qweight', 'model.layers.11.mlp.up_proj.qzeros', 'model.layers.2.self_attn.v_proj.qweight', 'model.layers.6.mlp.down_proj.scales', 'model.layers.24.self_attn.v_proj.qweight', 'model.layers.23.self_attn.v_proj.bias', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.20.self_attn.q_proj.qweight', 'model.layers.1.mlp.down_proj.bias', 'model.layers.5.mlp.down_proj.scales', 'model.layers.4.self_attn.q_proj.scales', 'model.layers.19.mlp.gate_proj.scales', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.19.mlp.down_proj.scales', 'model.layers.28.mlp.gate_proj.qweight', 'model.layers.30.mlp.gate_proj.qzeros', 'model.layers.10.self_attn.k_proj.qzeros', 'model.layers.17.mlp.up_proj.scales', 'model.layers.1.self_attn.q_proj.qzeros', 'model.layers.1.mlp.gate_proj.scales', 'model.layers.6.self_attn.v_proj.scales', 'model.layers.24.self_attn.k_proj.qzeros', 'model.layers.27.mlp.gate_proj.qweight', 'model.layers.1.mlp.up_proj.scales', 'model.layers.10.self_attn.q_proj.qweight', 'model.layers.17.mlp.up_proj.bias', 'model.layers.17.mlp.gate_proj.qzeros', 'model.layers.10.self_attn.q_proj.qzeros', 'model.layers.14.mlp.up_proj.scales', 'model.layers.27.mlp.down_proj.qzeros', 'model.layers.31.self_attn.k_proj.qweight', 'model.layers.30.mlp.gate_proj.qweight', 'model.layers.22.self_attn.o_proj.qzeros', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.13.mlp.up_proj.qzeros', 'model.layers.25.self_attn.o_proj.scales', 'model.layers.11.mlp.up_proj.qweight', 'model.layers.10.mlp.down_proj.scales', 'model.layers.18.self_attn.v_proj.bias', 'model.layers.22.self_attn.q_proj.scales', 'model.layers.29.self_attn.v_proj.bias', 'model.layers.4.self_attn.k_proj.qweight', 'model.layers.16.mlp.down_proj.qzeros', 'model.layers.15.mlp.down_proj.qweight', 'model.layers.9.mlp.gate_proj.scales', 'model.layers.10.self_attn.v_proj.qzeros', 'model.layers.2.mlp.down_proj.qweight', 'model.layers.3.self_attn.k_proj.scales', 'model.layers.25.self_attn.q_proj.bias', 'model.layers.28.self_attn.q_proj.qweight', 'model.layers.23.self_attn.o_proj.qzeros', 'model.layers.13.mlp.gate_proj.scales', 'model.layers.5.mlp.gate_proj.scales', 'model.layers.16.self_attn.k_proj.bias', 'model.layers.3.mlp.up_proj.qweight', 'model.layers.12.mlp.down_proj.qzeros', 'model.layers.9.mlp.down_proj.scales', 'model.layers.24.self_attn.v_proj.scales', 'model.layers.25.self_attn.v_proj.qweight', 'model.layers.1.mlp.gate_proj.qweight', 'model.layers.0.self_attn.k_proj.qzeros', 'model.layers.20.mlp.up_proj.qzeros', 'model.layers.23.self_attn.v_proj.qweight', 'model.layers.12.self_attn.v_proj.qweight', 'model.layers.26.self_attn.k_proj.qweight', 'model.layers.28.self_attn.q_proj.qzeros', 'model.layers.11.self_attn.o_proj.bias', 'model.layers.19.self_attn.k_proj.bias', 'model.layers.5.self_attn.q_proj.qzeros', 'model.layers.10.self_attn.o_proj.qzeros', 'model.layers.19.mlp.down_proj.bias', 'model.layers.10.mlp.gate_proj.qweight', 'model.layers.27.mlp.gate_proj.scales', 'model.layers.31.self_attn.v_proj.qzeros', 'model.layers.25.self_attn.o_proj.qzeros', 'model.layers.23.self_attn.q_proj.qweight', 'model.layers.27.self_attn.q_proj.bias', 'model.layers.28.self_attn.v_proj.scales', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.6.mlp.up_proj.qzeros', 'model.layers.10.mlp.up_proj.bias', 'model.layers.10.mlp.down_proj.qzeros', 'model.layers.16.mlp.gate_proj.bias', 'model.layers.6.mlp.up_proj.bias', 'model.layers.16.self_attn.v_proj.qweight', 'model.layers.3.mlp.up_proj.scales', 'model.layers.8.self_attn.o_proj.qweight', 'model.layers.6.mlp.gate_proj.scales', 'model.layers.5.self_attn.k_proj.qzeros', 'model.layers.6.mlp.up_proj.qweight', 'model.layers.4.mlp.gate_proj.scales', 'model.layers.1.mlp.down_proj.scales', 'model.layers.9.mlp.down_proj.qzeros', 'model.layers.9.self_attn.v_proj.scales', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.20.mlp.down_proj.qzeros', 'model.layers.14.mlp.down_proj.qweight', 'model.layers.27.self_attn.k_proj.scales', 'model.layers.28.mlp.gate_proj.scales', 'model.layers.10.self_attn.o_proj.scales', 'model.layers.25.mlp.gate_proj.qzeros', 'model.layers.28.self_attn.k_proj.bias', 'model.layers.9.self_attn.k_proj.qweight', 'model.layers.7.mlp.up_proj.scales', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.12.self_attn.q_proj.scales', 'model.layers.13.mlp.down_proj.qweight', 'model.layers.25.mlp.down_proj.qweight', 'model.layers.3.mlp.down_proj.scales', 'model.layers.30.mlp.down_proj.qweight', 'model.layers.13.self_attn.o_proj.bias', 'model.layers.4.mlp.up_proj.bias', 'model.layers.20.self_attn.k_proj.qweight', 'model.layers.4.self_attn.k_proj.scales', 'model.layers.29.self_attn.q_proj.qzeros', 'model.layers.5.mlp.up_proj.qweight', 'model.layers.18.mlp.up_proj.qzeros', 'model.layers.22.mlp.down_proj.bias', 'model.layers.5.self_attn.q_proj.qweight', 'model.layers.7.mlp.down_proj.scales', 'model.layers.17.self_attn.q_proj.scales', 'model.layers.16.mlp.up_proj.qweight', 'model.layers.2.mlp.up_proj.bias', 'model.layers.22.mlp.down_proj.qzeros', 'model.layers.13.self_attn.q_proj.qweight', 'model.layers.14.mlp.up_proj.qweight', 'model.layers.16.mlp.gate_proj.qweight', 'model.layers.4.self_attn.o_proj.bias', 'model.layers.11.self_attn.q_proj.qweight', 'model.layers.15.self_attn.q_proj.scales', 'model.layers.10.mlp.gate_proj.scales', 'model.layers.27.mlp.up_proj.qweight', 'model.layers.13.self_attn.v_proj.qweight', 'model.layers.18.self_attn.q_proj.qzeros', 'model.layers.15.self_attn.o_proj.qweight', 'model.layers.6.self_attn.o_proj.scales', 'model.layers.10.mlp.down_proj.bias', 'model.layers.11.self_attn.o_proj.scales', 'model.layers.30.mlp.up_proj.bias', 'model.layers.23.self_attn.o_proj.scales', 'model.layers.6.mlp.down_proj.bias', 'model.layers.12.self_attn.k_proj.qzeros', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.31.self_attn.k_proj.bias', 'model.layers.28.mlp.down_proj.scales', 'model.layers.1.self_attn.k_proj.scales', 'model.layers.0.mlp.down_proj.qweight', 'model.layers.4.mlp.up_proj.scales', 'model.layers.23.self_attn.v_proj.scales', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.16.mlp.gate_proj.qzeros', 'model.layers.17.self_attn.o_proj.qzeros', 'model.layers.8.mlp.gate_proj.qweight', 'model.layers.31.self_attn.o_proj.qweight', 'model.layers.18.self_attn.o_proj.bias', 'model.layers.20.self_attn.v_proj.scales', 'model.layers.26.mlp.down_proj.qweight', 'model.layers.19.mlp.up_proj.qzeros', 'model.layers.5.mlp.down_proj.qweight', 'model.layers.8.self_attn.v_proj.scales', 'model.layers.21.mlp.gate_proj.scales', 'model.layers.21.self_attn.q_proj.scales', 'model.layers.21.mlp.down_proj.scales', 'model.layers.14.mlp.down_proj.qzeros', 'model.layers.14.self_attn.k_proj.qzeros', 'model.layers.26.self_attn.q_proj.qweight', 'model.layers.13.self_attn.q_proj.scales', 'model.layers.19.mlp.gate_proj.qweight', 'model.layers.3.self_attn.v_proj.qzeros', 'model.layers.9.mlp.up_proj.bias', 'model.layers.7.self_attn.k_proj.qzeros', 'model.layers.30.mlp.down_proj.bias', 'model.layers.6.mlp.down_proj.qweight', 'model.layers.9.mlp.down_proj.qweight', 'model.layers.25.mlp.up_proj.bias', 'model.layers.10.mlp.up_proj.qweight', 'model.layers.5.mlp.gate_proj.qweight', 'model.layers.5.self_attn.o_proj.qzeros', 'model.layers.29.self_attn.v_proj.qweight', 'model.layers.6.self_attn.k_proj.scales', 'model.layers.5.mlp.up_proj.bias', 'model.layers.1.mlp.up_proj.bias', 'model.layers.6.self_attn.k_proj.qweight', 'model.layers.31.self_attn.q_proj.qweight', 'model.layers.20.self_attn.o_proj.bias', 'model.layers.22.self_attn.o_proj.scales', 'model.layers.28.mlp.down_proj.qweight', 'model.layers.0.mlp.gate_proj.scales', 'model.layers.11.mlp.gate_proj.bias', 'model.layers.15.mlp.gate_proj.qzeros', 'model.layers.20.mlp.up_proj.qweight', 'model.layers.27.self_attn.k_proj.qzeros', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.21.mlp.gate_proj.qweight', 'model.layers.15.mlp.gate_proj.bias', 'model.layers.22.self_attn.o_proj.bias', 'model.layers.25.self_attn.k_proj.scales', 'model.layers.18.mlp.up_proj.scales', 'model.layers.17.self_attn.o_proj.qweight', 'model.layers.15.mlp.gate_proj.scales', 'model.layers.2.self_attn.q_proj.qzeros', 'model.layers.23.mlp.up_proj.qzeros', 'model.layers.22.mlp.down_proj.qweight', 'model.layers.8.mlp.gate_proj.scales', 'model.layers.9.mlp.up_proj.scales', 'model.layers.17.mlp.gate_proj.bias', 'model.layers.28.mlp.up_proj.qzeros', 'model.layers.21.self_attn.k_proj.bias', 'model.layers.22.self_attn.k_proj.scales', 'model.layers.20.mlp.down_proj.qweight', 'model.layers.6.self_attn.q_proj.qzeros', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.10.self_attn.o_proj.qweight', 'model.layers.19.mlp.gate_proj.qzeros', 'model.layers.20.self_attn.v_proj.qweight', 'model.layers.30.self_attn.v_proj.scales', 'model.layers.7.self_attn.q_proj.scales', 'model.layers.21.mlp.up_proj.qzeros', 'model.layers.15.mlp.up_proj.scales', 'model.layers.21.mlp.down_proj.qzeros', 'model.layers.12.mlp.gate_proj.bias', 'model.layers.12.self_attn.v_proj.qzeros', 'model.layers.19.self_attn.q_proj.qweight', 'model.layers.20.self_attn.q_proj.bias', 'model.layers.5.self_attn.o_proj.qweight', 'model.layers.20.self_attn.k_proj.bias', 'model.layers.30.self_attn.v_proj.qweight', 'model.layers.24.self_attn.q_proj.bias', 'model.layers.12.self_attn.o_proj.qzeros', 'model.layers.31.mlp.down_proj.qzeros', 'model.layers.9.self_attn.o_proj.bias', 'model.layers.13.mlp.up_proj.scales', 'model.layers.17.self_attn.v_proj.scales', 'model.layers.3.self_attn.o_proj.bias', 'model.layers.16.self_attn.q_proj.qweight', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.10.self_attn.q_proj.scales', 'model.layers.29.mlp.up_proj.bias', 'model.layers.6.self_attn.q_proj.scales', 'model.layers.30.mlp.gate_proj.bias', 'model.layers.11.self_attn.k_proj.scales', 'model.layers.5.self_attn.k_proj.scales', 'model.layers.3.self_attn.o_proj.scales', 'model.layers.13.self_attn.k_proj.qweight', 'model.layers.12.mlp.down_proj.scales', 'model.layers.15.self_attn.v_proj.qzeros', 'model.layers.18.mlp.down_proj.qzeros', 'model.layers.22.self_attn.v_proj.bias', 'model.layers.3.mlp.down_proj.bias', 'model.layers.13.self_attn.v_proj.scales', 'model.layers.29.self_attn.v_proj.scales', 'model.layers.8.self_attn.v_proj.qzeros', 'model.layers.6.mlp.gate_proj.qweight', 'model.layers.19.mlp.gate_proj.bias', 'model.layers.17.self_attn.k_proj.qzeros', 'model.layers.20.mlp.gate_proj.scales', 'model.layers.5.mlp.up_proj.scales', 'model.layers.21.self_attn.k_proj.qzeros', 'model.layers.21.mlp.down_proj.bias']\n",
      "- This IS expected if you are initializing LlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "weight is on the meta device, we need a `value` to put in on 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32me:\\src\\transformer-sketchbook\\notebooks\\generating_text.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/generating_text.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model_name_or_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m../models/Wizard-Vicuna-7B-Uncensored-GPTQ\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/generating_text.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# To use a different branch, change revision\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/generating_text.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# For example: revision=\"main\"\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/generating_text.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model \u001b[39m=\u001b[39m AutoModelForCausalLM\u001b[39m.\u001b[39;49mfrom_pretrained(model_name_or_path,\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/generating_text.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                                              device_map\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/generating_text.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                                              trust_remote_code\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/generating_text.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                                              revision\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmain\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/generating_text.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(model_name_or_path, use_fast\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/generating_text.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m prompt \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mTell me about AI\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\danm\\Downloads\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m    470\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 471\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    472\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39mmodel_args, config\u001b[39m=\u001b[39mconfig, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhub_kwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    473\u001b[0m     )\n\u001b[0;32m    474\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    475\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized configuration class \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m for this kind of AutoModel: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    476\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel type should be one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(c\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    477\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\danm\\Downloads\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\transformers\\modeling_utils.py:2846\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2844\u001b[0m \u001b[39m# Dispatch model with hooks on all devices if necessary\u001b[39;00m\n\u001b[0;32m   2845\u001b[0m \u001b[39mif\u001b[39;00m device_map \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 2846\u001b[0m     dispatch_model(model, device_map\u001b[39m=\u001b[39;49mdevice_map, offload_dir\u001b[39m=\u001b[39;49moffload_folder, offload_index\u001b[39m=\u001b[39;49moffload_index)\n\u001b[0;32m   2848\u001b[0m \u001b[39mif\u001b[39;00m output_loading_info:\n\u001b[0;32m   2849\u001b[0m     \u001b[39mif\u001b[39;00m loading_info \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\danm\\Downloads\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\accelerate\\big_modeling.py:370\u001b[0m, in \u001b[0;36mdispatch_model\u001b[1;34m(model, device_map, main_device, state_dict, offload_dir, offload_index, offload_buffers, preload_module_classes)\u001b[0m\n\u001b[0;32m    367\u001b[0m     weights_map \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    369\u001b[0m tied_params \u001b[39m=\u001b[39m find_tied_parameters(model)\n\u001b[1;32m--> 370\u001b[0m attach_align_device_hook_on_blocks(\n\u001b[0;32m    371\u001b[0m     model,\n\u001b[0;32m    372\u001b[0m     execution_device\u001b[39m=\u001b[39;49mexecution_device,\n\u001b[0;32m    373\u001b[0m     offload\u001b[39m=\u001b[39;49moffload,\n\u001b[0;32m    374\u001b[0m     offload_buffers\u001b[39m=\u001b[39;49moffload_buffers,\n\u001b[0;32m    375\u001b[0m     weights_map\u001b[39m=\u001b[39;49mweights_map,\n\u001b[0;32m    376\u001b[0m     preload_module_classes\u001b[39m=\u001b[39;49mpreload_module_classes,\n\u001b[0;32m    377\u001b[0m )\n\u001b[0;32m    378\u001b[0m \u001b[39m# Attaching the hook may break tied weights, so we retie them\u001b[39;00m\n\u001b[0;32m    379\u001b[0m retie_parameters(model, tied_params)\n",
      "File \u001b[1;32mc:\\Users\\danm\\Downloads\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\accelerate\\hooks.py:478\u001b[0m, in \u001b[0;36mattach_align_device_hook_on_blocks\u001b[1;34m(module, execution_device, offload, weights_map, offload_buffers, module_name, preload_module_classes)\u001b[0m\n\u001b[0;32m    471\u001b[0m \u001b[39mif\u001b[39;00m module_name \u001b[39min\u001b[39;00m execution_device \u001b[39mand\u001b[39;00m module_name \u001b[39min\u001b[39;00m offload \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m offload[module_name]:\n\u001b[0;32m    472\u001b[0m     hook \u001b[39m=\u001b[39m AlignDevicesHook(\n\u001b[0;32m    473\u001b[0m         execution_device\u001b[39m=\u001b[39mexecution_device[module_name],\n\u001b[0;32m    474\u001b[0m         offload_buffers\u001b[39m=\u001b[39moffload_buffers,\n\u001b[0;32m    475\u001b[0m         io_same_device\u001b[39m=\u001b[39m(module_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    476\u001b[0m         place_submodules\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    477\u001b[0m     )\n\u001b[1;32m--> 478\u001b[0m     add_hook_to_module(module, hook)\n\u001b[0;32m    479\u001b[0m     attach_execution_device_hook(module, execution_device[module_name])\n\u001b[0;32m    480\u001b[0m \u001b[39melif\u001b[39;00m module_name \u001b[39min\u001b[39;00m execution_device \u001b[39mand\u001b[39;00m module_name \u001b[39min\u001b[39;00m offload:\n",
      "File \u001b[1;32mc:\\Users\\danm\\Downloads\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\accelerate\\hooks.py:155\u001b[0m, in \u001b[0;36madd_hook_to_module\u001b[1;34m(module, hook, append)\u001b[0m\n\u001b[0;32m    152\u001b[0m     old_forward \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39mforward\n\u001b[0;32m    153\u001b[0m     module\u001b[39m.\u001b[39m_old_forward \u001b[39m=\u001b[39m old_forward\n\u001b[1;32m--> 155\u001b[0m module \u001b[39m=\u001b[39m hook\u001b[39m.\u001b[39;49minit_hook(module)\n\u001b[0;32m    156\u001b[0m module\u001b[39m.\u001b[39m_hf_hook \u001b[39m=\u001b[39m hook\n\u001b[0;32m    158\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(old_forward)\n\u001b[0;32m    159\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnew_forward\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n",
      "File \u001b[1;32mc:\\Users\\danm\\Downloads\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\accelerate\\hooks.py:251\u001b[0m, in \u001b[0;36mAlignDevicesHook.init_hook\u001b[1;34m(self, module)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moffload \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexecution_device \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    250\u001b[0m     \u001b[39mfor\u001b[39;00m name, _ \u001b[39min\u001b[39;00m named_module_tensors(module, recurse\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mplace_submodules):\n\u001b[1;32m--> 251\u001b[0m         set_module_tensor_to_device(module, name, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecution_device)\n\u001b[0;32m    252\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moffload:\n\u001b[0;32m    253\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moriginal_devices \u001b[39m=\u001b[39m {\n\u001b[0;32m    254\u001b[0m         name: param\u001b[39m.\u001b[39mdevice \u001b[39mfor\u001b[39;00m name, param \u001b[39min\u001b[39;00m named_module_tensors(module, recurse\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mplace_submodules)\n\u001b[0;32m    255\u001b[0m     }\n",
      "File \u001b[1;32mc:\\Users\\danm\\Downloads\\oobabooga_windows\\installer_files\\env\\lib\\site-packages\\accelerate\\utils\\modeling.py:140\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[1;34m(module, tensor_name, device, value, dtype)\u001b[0m\n\u001b[0;32m    137\u001b[0m old_value \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(module, tensor_name)\n\u001b[0;32m    139\u001b[0m \u001b[39mif\u001b[39;00m old_value\u001b[39m.\u001b[39mdevice \u001b[39m==\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mmeta\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m device \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mmeta\u001b[39m\u001b[39m\"\u001b[39m, torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mmeta\u001b[39m\u001b[39m\"\u001b[39m)] \u001b[39mand\u001b[39;00m value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mtensor_name\u001b[39m}\u001b[39;00m\u001b[39m is on the meta device, we need a `value` to put in on \u001b[39m\u001b[39m{\u001b[39;00mdevice\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    142\u001b[0m \u001b[39mif\u001b[39;00m value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m         \u001b[39m# For compatibility with PyTorch load_state_dict which converts state dict dtype to existing dtype in model\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: weight is on the meta device, we need a `value` to put in on 0."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_name_or_path = \"../models/Wizard-Vicuna-7B-Uncensored-GPTQ\"\n",
    "# To use a different branch, change revision\n",
    "# For example: revision=\"main\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path,\n",
    "                                             device_map=\"auto\",\n",
    "                                             trust_remote_code=True,\n",
    "                                             revision=\"main\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
    "\n",
    "prompt = \"Tell me about AI\"\n",
    "prompt_template=f'''A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
    "\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "<s> ### instruction : what is the outcome of pitcher 663432 pitching to batter 596115 ### input : Top of the 1 inning with 2 outs ### output : 663432 throws a 87 miles per hour Slider for a strike, 663432 throws a 86 miles per hour Slider for a strike, 663432 throws a 86 miles per hour Slider for a ball, 663432 throws a 86 miles per hour Slider for a strike and 596115 strikeout, event : strikeout, strikeout, event : strikeout, event : strikeout, strikeout, event : strikeout, strikeout, event : strikeout, play, event : strikeout double play, event : strikeout double play, event : strikeout double play, event\n"
     ]
    }
   ],
   "source": [
    "# encode context the generation is conditioned on\n",
    "model_inputs = tokenizer(prompt_template, return_tensors='pt').to(torch_device)\n",
    "\n",
    "# generate 40 new tokens\n",
    "greedy_output = model.generate(**model_inputs, max_new_tokens=95)\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(greedy_output[0], skip_special_tokens=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beam search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "### instruction : what is the outcome of pitcher 663432 pitching to batter 596115 ### input : Top of the 1 inning with 2 outs ### output : 663432 throws a 88 miles per hour Slider for a strike, 663432 throws a 88 miles per hour Slider for a strike, 663432 throws a 88 miles per hour Slider for a ball, 663432 throws a 88 miles per hour Slider for a strike, 663432 throws a 88 miles per hour Slider for a strike, 663432 throws a 88 miles per hour Slider\n"
     ]
    }
   ],
   "source": [
    "beam_output = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=65,\n",
    "    num_beams=5,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(beam_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "### instruction : what is the outcome of pitcher 663432 pitching to batter 596115 ### input : Top of the 8 inning with 2 outs ### output : 663432 throws a 88 miles per hour Slider for a strike, 663432 throws a 88 miles per hour Slider for for strike, 663432 throws a 88 miles per hour Cutter for a ball, 663432 throws a 88 miles per hour Slider and 596115 hits into a field out, event : field out, event : field out, out, event : field out\n"
     ]
    }
   ],
   "source": [
    "beam_output = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=65,\n",
    "    num_beams=5,\n",
    "    no_repeat_ngram_size=10,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(beam_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: ### instruction : what is the outcome of pitcher 663432 pitching to batter 596115 ### input : Top of the 8 inning with 2 outs ### output : 663432 throws a 88 miles per hour Slider for a strike, 663432 throws a 88 miles per hour Slider for for strike, 663432 throws a 88 miles per hour Cutter for a ball, 663432 throws a 88 miles per hour Slider and 596115 hits into a field out, event : field out, event : field out, out, event : field out\n",
      "1: ### instruction : what is the outcome of pitcher 663432 pitching to batter 596115 ### input : Top of the 8 inning with 2 outs ### output : 663432 throws a 88 miles per hour Slider for a strike, 663432 throws a 88 miles per hour Slider for for strike, 663432 throws a 88 miles per hour Changeup for a ball, 663432 throws a 88 miles per hour Slider and 596115 hits into a field out, event : field out, event : field out, out, event : field out\n",
      "2: ### instruction : what is the outcome of pitcher 663432 pitching to batter 596115 ### input : Top of the 8 inning with 2 outs ### output : 663432 throws a 88 miles per hour Slider for a strike, 663432 throws a 88 miles per hour Slider for stealing strike, 663432 throws a 88 miles per hour Cutter for a ball, 663432 throws a 88 miles per hour Slider and 596115 hits into a field out, event : field out, event : field out, out, event : field out\n",
      "3: ### instruction : what is the outcome of pitcher 663432 pitching to batter 596115 ### input : Top of the 8 inning with 2 outs ### output : 663432 throws a 88 miles per hour Slider for a strike, 663432 throws a 88 miles per hour Slider for for strike, 663432 throws a 88 miles per hour Cutter for a ball, 663432 throws a 88 miles per hour Slider and 596115 hits into a field out, event : field out, event : field out, out, field out, event\n",
      "4: ### instruction : what is the outcome of pitcher 663432 pitching to batter 596115 ### input : Top of the 8 inning with 2 outs ### output : 663432 throws a 88 miles per hour Slider for a strike, 663432 throws a 88 miles per hour Slider for for strike, 663432 throws a 88 miles per hour Cutter for a ball, 663432 throws a 88 miles per hour Slider and 596115 hits into a field out, event : field out, event : field out, out, hits : field out\n"
     ]
    }
   ],
   "source": [
    "# set return_num_sequences > 1\n",
    "beam_outputs = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=65,\n",
    "    num_beams=5,\n",
    "    no_repeat_ngram_size=10,\n",
    "    num_return_sequences=5,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "# now we have 3 output sequences\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "for i, beam_output in enumerate(beam_outputs):\n",
    "  print(\"{}: {}\".format(i, tokenizer.decode(beam_output, skip_special_tokens=True)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import set_seed\n",
    "set_seed(42)\n",
    "\n",
    "# activate sampling and deactivate top_k by setting top_k sampling to 0\n",
    "sample_output = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=40,\n",
    "    do_sample=True,\n",
    "    top_k=0\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed to reproduce results. Feel free to change the seed though to get different results\n",
    "set_seed(42)\n",
    "\n",
    "# use temperature to decrease the sensitivity to low probability candidates\n",
    "sample_output = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=40,\n",
    "    do_sample=True,\n",
    "    top_k=0,\n",
    "    temperature=0.6,\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top-K Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed to reproduce results. Feel free to change the seed though to get different results\n",
    "set_seed(42)\n",
    "\n",
    "# set top_k to 50\n",
    "sample_output = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=40,\n",
    "    do_sample=True,\n",
    "    top_k=50\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top-p (nucleus) sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed to reproduce results. Feel free to change the seed though to get different results\n",
    "set_seed(42)\n",
    "\n",
    "# set top_k to 50\n",
    "sample_output = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=40,\n",
    "    do_sample=True,\n",
    "    top_p=0.92,\n",
    "    top_k=0\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed to reproduce results. Feel free to change the seed though to get different results\n",
    "set_seed(42)\n",
    "\n",
    "# set top_k = 50 and set top_p = 0.95 and num_return_sequences = 3\n",
    "sample_outputs = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=40,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    num_return_sequences=3,\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "for i, sample_output in enumerate(sample_outputs):\n",
    "  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save a custom decoding strategy with your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, GenerationConfig\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"my_account/my_model\")\n",
    "generation_config = GenerationConfig(\n",
    "    max_new_tokens=50, do_sample=True, top_k=50, eos_token_id=model.config.eos_token_id\n",
    ")\n",
    "generation_config.save_pretrained(\"my_account/my_model\", push_to_hub=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
