{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install Everything You Need"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install tokenizers\n",
        "%pip install transformers\n",
        "%pip install datasets --upgrade"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gI1Tp54IiVBj"
      },
      "source": [
        "## Train a custom tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "Exception",
          "evalue": "The system cannot find the path specified. (os error 3)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32me:\\src\\transformer-sketchbook\\notebooks\\training_an_slm.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/training_an_slm.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m trainer \u001b[39m=\u001b[39m BpeTrainer(special_tokens\u001b[39m=\u001b[39m[    \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/training_an_slm.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m<s>\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/training_an_slm.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m<pad>\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/training_an_slm.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m<mask>\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/training_an_slm.ipynb#W4sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     ])\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/training_an_slm.ipynb#W4sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m tokenizer\u001b[39m.\u001b[39mtrain(files\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mtwenty_years_of_baseball_structed_data.txt\u001b[39m\u001b[39m\"\u001b[39m], trainer\u001b[39m=\u001b[39mtrainer)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/training_an_slm.ipynb#W4sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m tokenizer\u001b[39m.\u001b[39;49msave(\u001b[39m\"\u001b[39;49m\u001b[39m../models/mlb_short/tokenizer/tokenizer.json\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/training_an_slm.ipynb#W4sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m output \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mencode(\u001b[39m'\u001b[39m\u001b[39m{\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpitcher\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mjered weaver\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbatter\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39malcides escobar\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mp_throws\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mR\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstand\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mR\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39minning_topbot\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBot\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39minning\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: 5, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mouts_when_up\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: 1, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mon_1b\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mon_2b\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mon_3b\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhome_score\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: 0, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39maway_score\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: 2}, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mresult\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mevent\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfield_out\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mzone\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: 14, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdes\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAlcides Escobar grounds out softly, third baseman Maicer Izturis to first baseman Mark Trumbo.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mat_bat_number\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: 40, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpitch_number\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: 5, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpitch_name\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSlider\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhit_location\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: 5, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlaunch_speed\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlaunch_speed_angle\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mruns_scored\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: 0, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mat_bat\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcalled_strike\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcalled_strike\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfoul\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mball\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhit_into_play\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m], \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpitch_type\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFF\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFF\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSI\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSI\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSL\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m], \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrelease_speed\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: [88.3, 90.2, 90.2, 88.6, 80.5]}}\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/src/transformer-sketchbook/notebooks/training_an_slm.ipynb#W4sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mprint\u001b[39m(output\u001b[39m.\u001b[39mtokens)\n",
            "\u001b[1;31mException\u001b[0m: The system cannot find the path specified. (os error 3)"
          ]
        }
      ],
      "source": [
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from pathlib import Path\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "tokenizer = Tokenizer(BPE(unk_token=\"<unk>\"))\n",
        "\n",
        "tokenizer.pre_tokenizer = Whitespace()\n",
        "\n",
        "trainer = BpeTrainer(special_tokens=[    \n",
        "    \"<s>\",\n",
        "    \"<pad>\",\n",
        "    \"</s>\",\n",
        "    \"<unk>\",\n",
        "    \"<mask>\"\n",
        "    ])\n",
        "\n",
        "tokenizer.train(files=[\"twenty_years_of_baseball_structed_data.txt\"], trainer=trainer)\n",
        "tokenizer.save(\"../models/mlb_structured/tokenizer/tokenizer.json\")\n",
        "\n",
        "output = tokenizer.encode('{\"input\": {\"pitcher\": \"jered weaver\", \"batter\": \"alcides escobar\", \"p_throws\": \"R\", \"stand\": \"R\", \"inning_topbot\": \"Bot\", \"inning\": 5, \"outs_when_up\": 1, \"on_1b\": \"\", \"on_2b\": \"\", \"on_3b\": \"\", \"home_score\": 0, \"away_score\": 2}, \"result\": {\"event\": \"field_out\", \"type\": \"X\", \"zone\": 14, \"des\": \"Alcides Escobar grounds out softly, third baseman Maicer Izturis to first baseman Mark Trumbo.\", \"at_bat_number\": 40, \"pitch_number\": 5, \"pitch_name\": \"Slider\", \"hit_location\": 5, \"launch_speed\": \"\", \"launch_speed_angle\": \"\", \"runs_scored\": 0, \"at_bat\": [\"called_strike\", \"called_strike\", \"foul\", \"ball\", \"hit_into_play\"], \"pitch_type\": [\"FF\", \"FF\", \"SI\", \"SI\", \"SL\"], \"release_speed\": [88.3, 90.2, 90.2, 88.6, 80.5]}}')\n",
        "print(output.tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11481"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.get_vocab_size()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train a Transformer Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import RobertaConfig\n",
        "\n",
        "config = RobertaConfig(\n",
        "    vocab_size=11481,\n",
        "    max_position_embeddings=514,\n",
        "    num_attention_heads=12,\n",
        "    num_hidden_layers=6,\n",
        "    type_vocab_size=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import RobertaTokenizerFast\n",
        "\n",
        "tokenizer = RobertaTokenizerFast(tokenizer_file=\"./models/mlb/tokenizer/baseball.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bin c:\\Users\\NVIDIA\\Downloads\\text-generation-webui-1.6\\text-generation-webui-1.6\\installer_files\\env\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda117.dll\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`\n"
          ]
        }
      ],
      "source": [
        "from transformers import RobertaForCausalLM, RobertaForMaskedLM\n",
        "\n",
        "model = RobertaForCausalLM(config=config)\n",
        "# model = RobertaForMaskedLM(config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "52345305"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.num_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "data_file = {\"train\":\"./baseball_23_03.txt\"}\n",
        "# dataset = load_dataset(\"json\", data_files=data_file)\n",
        "dataset = load_dataset(\"text\", data_files=data_file)\n",
        "# raw_datasets = load_dataset(\n",
        "#             \"json\",\n",
        "#             data_files=data_file,\n",
        "#         )\n",
        "\n",
        "# raw_datasets = {}\n",
        "# raw_datasets[\"validation\"] = load_dataset(\n",
        "#     \"json\",\n",
        "#     data_files=data_file,\n",
        "#     split=f\"train[:{90}%]\",\n",
        "# )\n",
        "# raw_datasets[\"train\"] = load_dataset(\n",
        "#     \"json\",\n",
        "#     data_files=data_file,\n",
        "#     split=f\"train[:{10}%]\",\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3678821\n"
          ]
        }
      ],
      "source": [
        "print(len(dataset[\"train\"]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\NVIDIA\\Downloads\\text-generation-webui-1.6\\text-generation-webui-1.6\\installer_files\\env\\lib\\site-packages\\transformers\\data\\datasets\\language_modeling.py:119: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import LineByLineTextDataset\n",
        "\n",
        "dataset = LineByLineTextDataset(\n",
        "    tokenizer=tokenizer,\n",
        "    file_path=\"./baseball_23_03.txt\",\n",
        "    block_size=128,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        }
      ],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    tf32=True,\n",
        "    output_dir=\"./models/mlb\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=100,\n",
        "    per_device_train_batch_size=512,\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "    prediction_loss_only=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=dataset,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.train(resume_from_checkpoint=\"./models/mlb/checkpoint-503500\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.save_model(\"./models/mlb/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "fill_mask = pipeline(\n",
        "    \"fill-mask\",\n",
        "    model=\"./models/mlb/checkpoint-498000\",\n",
        "    tokenizer=tokenizer,\n",
        "    top_k=20,\n",
        ")\n",
        "\n",
        "fill_text = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=\"./models/mlb/checkpoint-498000\",\n",
        "    tokenizer=tokenizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "https://huggingface.co/blog/how-to-generate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "# add the EOS token as PAD token to avoid warnings\n",
        "model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=\"./models/mlb/checkpoint-498000\", pad_token_id=tokenizer.eos_token_id).to(torch_device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# encode context the generation is conditioned on\n",
        "model_inputs = tokenizer(f'<s> ###instruction: what is the outcome of pitcher 663432 pitching to batter 596115 ###input: Top of the {math.floor(random.randrange(1, 10))} inning with {math.floor(random.randrange(0, 3))} outs ###output: 663432 throws a\"', return_tensors='pt').to(torch_device)\n",
        "\n",
        "# generate 40 new tokens\n",
        "greedy_output = model.generate(**model_inputs, max_new_tokens=160)\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# activate beam search and early_stopping\n",
        "beam_output = model.generate(\n",
        "    **model_inputs,\n",
        "    max_new_tokens=40,\n",
        "    num_beams=5,\n",
        "    early_stopping=True\n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(beam_output[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# set no_repeat_ngram_size to 2\n",
        "beam_output = model.generate(\n",
        "    **model_inputs,\n",
        "    max_new_tokens=40,\n",
        "    num_beams=5,\n",
        "    no_repeat_ngram_size=2,\n",
        "    early_stopping=True\n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(beam_output[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# set return_num_sequences > 1\n",
        "beam_outputs = model.generate(\n",
        "    **model_inputs,\n",
        "    max_new_tokens=40,\n",
        "    num_beams=5,\n",
        "    no_repeat_ngram_size=5,\n",
        "    num_return_sequences=5,\n",
        "    early_stopping=True,\n",
        ")\n",
        "\n",
        "# now we have 3 output sequences\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "for i, beam_output in enumerate(beam_outputs):\n",
        "  print(\"{}: {}\".format(i, tokenizer.decode(beam_output, skip_special_tokens=True)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# set seed to reproduce results. Feel free to change the seed though to get different results\n",
        "from transformers import set_seed\n",
        "set_seed(42)\n",
        "for i in range(0, 15):\n",
        "    model_inputs = tokenizer(f'<s> ###instruction: what is the outcome of pitcher 663432 pitching to batter 596115 ###input: Top of the {math.floor(random.randrange(1, 10))} inning with {math.floor(random.randrange(0, 3))} outs ###output: 663432 throws a\"', return_tensors='pt').to(torch_device)\n",
        "\n",
        "    # activate sampling and deactivate top_k by setting top_k sampling to 0\n",
        "    sample_output = model.generate(\n",
        "        **model_inputs,\n",
        "        max_new_tokens=40,\n",
        "        do_sample=True,\n",
        "        top_k=100,\n",
        "        temperature=0.6,\n",
        "    )\n",
        "\n",
        "    print(\"Output:\\n\" + 100 * '-')\n",
        "    print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "set_seed(42)\n",
        "\n",
        "# use temperature to decrease the sensitivity to low probability candidates\n",
        "sample_output = model.generate(\n",
        "    **model_inputs,\n",
        "    max_new_tokens=40,\n",
        "    do_sample=True,\n",
        "    top_k=0,\n",
        "    temperature=0.6,\n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# set seed to reproduce results. Feel free to change the seed though to get different results\n",
        "set_seed(42)\n",
        "\n",
        "# set top_k to 50\n",
        "sample_output = model.generate(\n",
        "    **model_inputs,\n",
        "    max_new_tokens=40,\n",
        "    do_sample=True,\n",
        "    top_k=50\n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "set_seed(42)\n",
        "\n",
        "# set top_k to 50\n",
        "sample_output = model.generate(\n",
        "    **model_inputs,\n",
        "    max_new_tokens=40,\n",
        "    do_sample=True,\n",
        "    top_p=0.92,\n",
        "    top_k=0\n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# set seed to reproduce results. Feel free to change the seed though to get different results\n",
        "set_seed(42)\n",
        "\n",
        "# set top_k = 50 and set top_p = 0.95 and num_return_sequences = 3\n",
        "sample_outputs = model.generate(\n",
        "    **model_inputs,\n",
        "    max_new_tokens=40,\n",
        "    do_sample=True,\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        "    num_return_sequences=3,\n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(0, 50):\n",
        "    text = fill_text(f\"<s> ###instruction: what is the outcome of pitcher 663432 pitching to batter 596115 ###input: Top of the {math.floor(random.randrange(1, 10))} inning with {math.floor(random.randrange(0, 3))} outs ###output: 663432 throws a\", max_new_tokens=25, top_k=10, temperature=1.25, do_sample=True, epsilon_cutoff=9e-4, encoder_repetition_penalty=0.1)\n",
        "    for t in text:\n",
        "        print(t)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPqbqeA0VB70ho26cHWVp02",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "smallBERTa_Pretraining.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
